{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf44004",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import SimpleITK as sitk\n",
    "from medpy.metric import binary\n",
    "from scipy.ndimage import label\n",
    "\n",
    "# Save NumPy mask array as NIfTI file\n",
    "def save_array_to_nii(mask_array, nii_template_path, nii_save_path):\n",
    "    sitk_image_object = sitk.ReadImage(nii_template_path)\n",
    "    output_spacing = sitk_image_object.GetSpacing()\n",
    "    output_direction = sitk_image_object.GetDirection()\n",
    "    output_origin = sitk_image_object.GetOrigin()\n",
    "\n",
    "    nrrd_output = sitk.GetImageFromArray(mask_array.astype(np.uint8))\n",
    "    nrrd_output.SetSpacing(output_spacing)\n",
    "    nrrd_output.SetDirection(output_direction)\n",
    "    nrrd_output.SetOrigin(output_origin)\n",
    "\n",
    "    sitk.WriteImage(nrrd_output, nii_save_path, True)  # save with compression\n",
    "    print(f\"Saved: {nii_save_path}\")\n",
    "\n",
    "# Keep only the largest connected component in a binary mask\n",
    "def largest_connected_component(binary_mask: np.ndarray) -> np.ndarray:\n",
    "    sitk_mask = sitk.GetImageFromArray(binary_mask.astype(np.uint8))\n",
    "\n",
    "    cc_filter = sitk.ConnectedComponentImageFilter()\n",
    "    labeled = cc_filter.Execute(sitk_mask)\n",
    "\n",
    "    stats = sitk.LabelShapeStatisticsImageFilter()\n",
    "    stats.Execute(labeled)\n",
    "\n",
    "    if stats.GetNumberOfLabels() == 0:\n",
    "        return np.zeros_like(binary_mask, dtype=bool)\n",
    "\n",
    "    largest_label = max(stats.GetLabels(), key=lambda l: stats.GetPhysicalSize(l))\n",
    "    largest_cc = labeled == largest_label\n",
    "    largest_cc_arr = sitk.GetArrayFromImage(largest_cc)\n",
    "    return largest_cc_arr.astype(bool)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7256f033-ec18-48c7-a2f4-866f901c437c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "341f10d7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import SimpleITK as sitk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from medpy.metric import binary\n",
    "\n",
    "# Fix numpy bool warning\n",
    "np.bool = bool  \n",
    "\n",
    "# Assume largest_connected_component() is already defined elsewhere\n",
    "\n",
    "# --- Directories ---\n",
    "seg_dir = \"/home/zhongyi/Desktop/nnunetv1/nnUNet_raw_data_base/nnUNet_test_data/test_seg_in_nii_raw_910_curated\"\n",
    "label_dir = \"/home/zhongyi/Desktop/nnunetv1/nnUNet_raw_data_base/nnUNet_test_data/test_seg_in_nii_raw_912_curated\"\n",
    "\n",
    "# --- Settings ---\n",
    "all_classes = [1, 2]   # muscle classes\n",
    "records = []\n",
    "\n",
    "# --- Iterate over segmentation results ---\n",
    "seg_files = sorted(glob.glob(os.path.join(seg_dir, \"*.nii.gz\")))\n",
    "\n",
    "for seg_path in seg_files:\n",
    "    seg_name = os.path.basename(seg_path)\n",
    "    \n",
    "    # Extract patient ID\n",
    "    pid = \"_\".join(seg_name.split(\"_\")[:3])\n",
    "    if \"ID\" in pid:\n",
    "        pid = pid.replace(\"water_L4L5\", \"\")\n",
    "    if \"_T\" in pid or \"word\" in pid:\n",
    "        pid = \"_\".join(seg_name.split(\"_\")[:2])\n",
    "    if pid[0] == \"s\":\n",
    "        pid = pid.split(\"_\")[0]    \n",
    "    pid = pid.replace(\"_L4L5\", \"\")   \n",
    "\n",
    "    # Find corresponding ground truth label\n",
    "    label_candidates = glob.glob(os.path.join(label_dir, f\"{pid}*.nii.gz\"))\n",
    "    if not label_candidates:\n",
    "        print(f\"❌ No ground truth label found for {pid}\")\n",
    "        continue\n",
    "    label_path = label_candidates[0]\n",
    "\n",
    "    # Load segmentation and label arrays\n",
    "    seg_arr = sitk.GetArrayFromImage(sitk.ReadImage(seg_path))\n",
    "    label_arr = sitk.GetArrayFromImage(sitk.ReadImage(label_path))\n",
    "\n",
    "    dsc_values = {}\n",
    "    decrease_values = {}\n",
    "\n",
    "    # --- Per-class evaluation ---\n",
    "    for cls in all_classes:\n",
    "        seg_bin = (seg_arr == cls)\n",
    "        label_bin = (label_arr == cls)\n",
    "\n",
    "        seg_bin_lcc = largest_connected_component(seg_bin)\n",
    "        label_bin_lcc = largest_connected_component(label_bin)\n",
    "\n",
    "        # Smoothness check: cross-sectional area should not jump too much\n",
    "        slice_areas = np.array([np.sum(seg_bin[z, :, :]) for z in range(seg_bin.shape[0])])\n",
    "        ratios = slice_areas[1:] / (slice_areas[:-1] + 1e-8)  # prevent div by zero\n",
    "        decreased = np.all(ratios <= 1.25)  # criterion: max 1.25x increase\n",
    "\n",
    "        if np.sum(label_bin_lcc) == 0:\n",
    "            dsc = np.nan\n",
    "            print(f\"⚠️ {pid} - Class {cls} not present in ground truth. DSC: NaN\")\n",
    "        else:\n",
    "            try:\n",
    "                dsc = binary.dc(seg_bin_lcc, label_bin_lcc)\n",
    "                print(f\"✅ {pid} - Class {cls} - DSC: {dsc:.4f} - Smooth: {decreased}\")\n",
    "            except Exception as e:\n",
    "                dsc = np.nan\n",
    "                print(f\"❌ Error computing DSC for {pid} - Class {cls}: {e}\")\n",
    "\n",
    "        dsc_values[cls] = dsc\n",
    "        decrease_values[cls] = decreased\n",
    "\n",
    "    # Mean DSC across classes\n",
    "    mean_dsc = np.nanmean(list(dsc_values.values()))\n",
    "\n",
    "    records.append({\n",
    "        \"pid\": pid,\n",
    "        \"dsc_class_1\": round(float(dsc_values.get(1, np.nan)), 4) if not np.isnan(dsc_values.get(1, np.nan)) else None,\n",
    "        \"dsc_class_2\": round(float(dsc_values.get(2, np.nan)), 4) if not np.isnan(dsc_values.get(2, np.nan)) else None,\n",
    "        \"mean_dsc\": round(float(mean_dsc), 4) if not np.isnan(mean_dsc) else None,\n",
    "        \"decrease_class_1\": decrease_values.get(1, False),\n",
    "        \"decrease_class_2\": decrease_values.get(2, False),\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cda7b0e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# --- Collect results into DataFrame ---\n",
    "df = pd.DataFrame(records)\n",
    "\n",
    "print(f\"\\n✅ Total PIDs evaluated: {len(df)}\")\n",
    "\n",
    "# Combine smoothness checks: require both classes satisfied\n",
    "df[\"decrease_all\"] = df[\"decrease_class_1\"] & df[\"decrease_class_2\"]\n",
    "\n",
    "# Sort: prioritize smooth predictions first, then higher mean DSC\n",
    "df_sorted = df.sort_values(\n",
    "    by=[\"decrease_all\", \"mean_dsc\"],\n",
    "    ascending=[False, False]\n",
    ").reset_index(drop=True)\n",
    "\n",
    "df_sorted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5919335c-1e23-48a3-b7e0-3feee532bf99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Assign dataset category based on PID naming rules ---\n",
    "def assign_dataset(pid: str) -> str:\n",
    "    if \"ID\" in pid:\n",
    "        return \"bedrest\"\n",
    "    elif \"T1\" in pid:\n",
    "        return \"T1W\"\n",
    "    elif \"T2\" in pid:\n",
    "        return \"T2W\"\n",
    "    elif pid.startswith(\"s\"):\n",
    "        return \"ct_tt\"\n",
    "    elif pid.startswith(\"word\"):\n",
    "        return \"ct_word\"\n",
    "    else:\n",
    "        return \"AFL\"\n",
    "\n",
    "# Apply dataset assignment\n",
    "df_sorted[\"dataset\"] = df_sorted[\"pid\"].apply(assign_dataset)\n",
    "df_sorted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70dffde3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Ensure required columns ---\n",
    "df[\"decrease_all\"] = df[\"decrease_class_1\"] & df[\"decrease_class_2\"]\n",
    "\n",
    "if \"dataset\" not in df.columns:\n",
    "    df[\"dataset\"] = df[\"pid\"].apply(assign_dataset)\n",
    "\n",
    "# --- Collect top cases per dataset ---\n",
    "df_top_list = []\n",
    "\n",
    "for dataset, group in df.groupby(\"dataset\"):\n",
    "    # Only keep cases with smoothness constraint + high DSC\n",
    "    df_true = group[(group[\"decrease_all\"]) & (group[\"mean_dsc\"] > 0.95)]\n",
    "    \n",
    "    # Top-N selection: keep 20% or at least 2 cases\n",
    "    top_n = max(2, int(len(group) * 0.2))\n",
    "    \n",
    "    df_top = df_true.sort_values(by=\"mean_dsc\", ascending=False).head(top_n)\n",
    "    df_top_list.append(df_top)\n",
    "\n",
    "# --- Combine all datasets ---\n",
    "df_top_all = pd.concat(df_top_list).reset_index(drop=True)\n",
    "df_top_all\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "418f092d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import shutil\n",
    "\n",
    "# =====================================\n",
    "# Copy Selected High-IoU Cases to Stage Dataset\n",
    "# =====================================\n",
    "\n",
    "# --- Input dirs ---\n",
    "img_dir = \"/home/zhongyi/Desktop/nnunetv1/nnUNet_raw_data_base/nnUNet_test_data/test_img_in_nii\"\n",
    "seg_dir = \"/home/zhongyi/Desktop/nnunetv1/nnUNet_raw_data_base/nnUNet_test_data/test_seg_in_nii_raw_912_curated\"\n",
    "\n",
    "# --- Output dirs (update per stage) ---\n",
    "stage = \"stage3\"   # e.g., \"stage2\", \"stage3\"\n",
    "base_out = f\"/home/zhongyi/Desktop/nnunetv1/nnUNet_raw_data_base/nnUNet_train_data_raw/MRI_highIOU_2class_nnsam2_{stage}\"\n",
    "out_img_dir = os.path.join(base_out, \"img_in_nii_L4-L5\")\n",
    "out_seg_dir = os.path.join(base_out, \"seg_in_nii_L4-L5\")\n",
    "\n",
    "# --- Create output dirs if not exist ---\n",
    "os.makedirs(out_img_dir, exist_ok=True)\n",
    "os.makedirs(out_seg_dir, exist_ok=True)\n",
    "\n",
    "# --- Iterate through selected PIDs ---\n",
    "for pid in df_top_all[\"pid\"]:\n",
    "    # Find matching image + segmentation files\n",
    "    img_matches = glob.glob(os.path.join(img_dir, f\"{pid}*.nii*\"))\n",
    "    seg_matches = glob.glob(os.path.join(seg_dir, f\"{pid}*.nii*\"))\n",
    "\n",
    "    # Copy image\n",
    "    if len(img_matches) == 1:\n",
    "        shutil.copy(img_matches[0], out_img_dir)\n",
    "        print(f\"✅ Copied image: {img_matches[0]}\")\n",
    "    elif len(img_matches) == 0:\n",
    "        print(f\"❌ Missing image for {pid}\")\n",
    "    else:\n",
    "        print(f\"⚠️ Multiple images for {pid}: {img_matches}\")\n",
    "\n",
    "    # Copy segmentation\n",
    "    if len(seg_matches) == 1:\n",
    "        shutil.copy(seg_matches[0], out_seg_dir)\n",
    "        print(f\"✅ Copied seg: {seg_matches[0]}\")\n",
    "    elif len(seg_matches) == 0:\n",
    "        print(f\"❌ Missing segmentation for {pid}\")\n",
    "    else:\n",
    "        print(f\"⚠️ Multiple segmentations for {pid}: {seg_matches}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e54f6c-a4e3-491b-8d9d-22e0eb1400b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
