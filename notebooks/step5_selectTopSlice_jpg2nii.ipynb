{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1e832a11",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 处理完 word_0002_L4L5，共 26 帧\n",
      "✅ 处理完 word_0003_L4L5，共 23 帧\n",
      "✅ 处理完 word_0004_L4L5，共 23 帧\n",
      "✅ 处理完 word_0005_L4L5，共 22 帧\n",
      "✅ 处理完 word_0006_L4L5，共 24 帧\n",
      "✅ 处理完 word_0008_L4L5，共 21 帧\n",
      "✅ 处理完 word_0009_L4L5，共 25 帧\n",
      "✅ 处理完 word_0010_L4L5，共 22 帧\n",
      "✅ 处理完 word_0011_L4L5，共 23 帧\n",
      "✅ 处理完 word_0012_L4L5，共 24 帧\n",
      "✅ 处理完 word_0013_L4L5，共 24 帧\n",
      "✅ 处理完 word_0018_L4L5，共 23 帧\n",
      "✅ 处理完 word_0020_L4L5，共 23 帧\n",
      "✅ 处理完 word_0022_L4L5，共 24 帧\n",
      "✅ 处理完 word_0026_L4L5，共 24 帧\n",
      "✅ 处理完 word_0027_L4L5，共 22 帧\n",
      "✅ 处理完 word_0028_L4L5，共 24 帧\n",
      "✅ 处理完 word_0029_L4L5，共 22 帧\n",
      "✅ 处理完 word_0030_L4L5，共 24 帧\n",
      "✅ 处理完 word_0032_L4L5，共 23 帧\n",
      "✅ 处理完 word_0036_L4L5，共 24 帧\n",
      "✅ 处理完 word_0038_L4L5，共 24 帧\n",
      "✅ 处理完 word_0040_L4L5，共 23 帧\n",
      "✅ 处理完 word_0041_L4L5，共 23 帧\n",
      "✅ 处理完 word_0042_L4L5，共 24 帧\n",
      "✅ 处理完 word_0044_L4L5，共 22 帧\n",
      "✅ 处理完 word_0046_L4L5，共 24 帧\n",
      "✅ 处理完 word_0047_L4L5，共 23 帧\n",
      "✅ 处理完 word_0049_L4L5，共 23 帧\n",
      "✅ 处理完 word_0051_L4L5，共 21 帧\n",
      "✅ 处理完 word_0053_L4L5，共 22 帧\n",
      "✅ 处理完 word_0055_L4L5，共 22 帧\n",
      "✅ 处理完 word_0056_L4L5，共 24 帧\n",
      "✅ 处理完 word_0058_L4L5，共 22 帧\n",
      "✅ 处理完 word_0059_L4L5，共 22 帧\n",
      "✅ 处理完 word_0061_L4L5，共 23 帧\n",
      "✅ 处理完 word_0062_L4L5，共 24 帧\n",
      "✅ 处理完 word_0063_L4L5，共 22 帧\n",
      "✅ 处理完 word_0064_L4L5，共 25 帧\n",
      "✅ 处理完 word_0065_L4L5，共 26 帧\n",
      "✅ 处理完 word_0067_L4L5，共 24 帧\n",
      "✅ 处理完 word_0068_L4L5，共 24 帧\n",
      "✅ 处理完 word_0070_L4L5，共 24 帧\n",
      "✅ 处理完 word_0071_L4L5，共 23 帧\n",
      "✅ 处理完 word_0072_L4L5，共 24 帧\n",
      "✅ 处理完 word_0073_L4L5，共 23 帧\n",
      "✅ 处理完 word_0078_L4L5，共 24 帧\n",
      "✅ 处理完 word_0079_L4L5，共 23 帧\n",
      "⚠️ 跳过 word_0081_L4L5，缺少 IOU 或 mapping 文件\n",
      "✅ 处理完 word_0082_L4L5，共 22 帧\n",
      "✅ 处理完 word_0084_L4L5，共 22 帧\n",
      "✅ 处理完 word_0086_L4L5，共 23 帧\n",
      "✅ 处理完 word_0087_L4L5，共 22 帧\n",
      "✅ 处理完 word_0089_L4L5，共 24 帧\n",
      "✅ 处理完 word_0090_L4L5，共 22 帧\n",
      "✅ 处理完 word_0091_L4L5，共 24 帧\n",
      "✅ 处理完 word_0093_L4L5，共 22 帧\n",
      "✅ 处理完 word_0094_L4L5，共 23 帧\n",
      "✅ 处理完 word_0095_L4L5，共 24 帧\n",
      "✅ 处理完 word_0096_L4L5，共 24 帧\n",
      "✅ 处理完 word_0100_L4L5，共 22 帧\n",
      "✅ 处理完 word_0101_L4L5，共 23 帧\n",
      "✅ 处理完 word_0102_L4L5，共 21 帧\n",
      "✅ 处理完 word_0104_L4L5，共 23 帧\n",
      "✅ 处理完 word_0105_L4L5，共 22 帧\n",
      "✅ 处理完 word_0106_L4L5，共 22 帧\n",
      "✅ 处理完 word_0107_L4L5，共 21 帧\n",
      "✅ 处理完 word_0108_L4L5，共 23 帧\n",
      "✅ 处理完 word_0109_L4L5，共 25 帧\n",
      "✅ 处理完 word_0111_L4L5，共 23 帧\n",
      "✅ 处理完 word_0113_L4L5，共 26 帧\n",
      "✅ 处理完 word_0114_L4L5，共 24 帧\n",
      "✅ 处理完 word_0115_L4L5，共 23 帧\n",
      "✅ 处理完 word_0116_L4L5，共 20 帧\n",
      "✅ 处理完 word_0117_L4L5，共 23 帧\n",
      "✅ 处理完 word_0118_L4L5，共 23 帧\n",
      "✅ 处理完 word_0119_L4L5，共 21 帧\n",
      "✅ 处理完 word_0121_L4L5，共 24 帧\n",
      "✅ 处理完 word_0122_L4L5，共 24 帧\n",
      "✅ 处理完 word_0123_L4L5，共 24 帧\n",
      "✅ 处理完 word_0125_L4L5，共 22 帧\n",
      "✅ 处理完 word_0126_L4L5，共 26 帧\n",
      "✅ 处理完 word_0127_L4L5，共 24 帧\n",
      "✅ 处理完 word_0128_L4L5，共 23 帧\n",
      "✅ 处理完 word_0130_L4L5，共 23 帧\n",
      "✅ 处理完 word_0132_L4L5，共 22 帧\n",
      "✅ 处理完 word_0133_L4L5，共 23 帧\n",
      "✅ 处理完 word_0134_L4L5，共 22 帧\n",
      "✅ 处理完 word_0135_L4L5，共 23 帧\n",
      "✅ 处理完 word_0136_L4L5，共 25 帧\n",
      "✅ 处理完 word_0138_L4L5，共 24 帧\n",
      "✅ 处理完 word_0140_L4L5，共 24 帧\n",
      "✅ 处理完 word_0142_L4L5，共 24 帧\n",
      "✅ 处理完 word_0143_L4L5，共 26 帧\n",
      "✅ 处理完 word_0144_L4L5，共 22 帧\n",
      "✅ 处理完 word_0145_L4L5，共 23 帧\n",
      "✅ 处理完 word_0146_L4L5，共 23 帧\n",
      "✅ 处理完 word_0147_L4L5，共 23 帧\n",
      "✅ 处理完 word_0148_L4L5，共 23 帧\n",
      "✅ 处理完 word_0150_L4L5，共 24 帧\n",
      "\n",
      "📄 保存所有合并结果至 videos/CT_word/data_in_jpg_2class/CT_word_2class_IOU_all_pid_with_full_mapping_1seed_1_slice_prompt.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "dataset = 'AFL_MRI'\n",
    "dataset = 'Bedrest'\n",
    "dataset = 'MRI515_T1'\n",
    "dataset = 'MRI515_T2'\n",
    "# dataset = 'MRI515_T2'\n",
    "dataset = 'CT_word'\n",
    "# dataset = 'CT_TT'\n",
    "\n",
    "data_dir = f'videos/{dataset}/data_in_jpg_2class'\n",
    "seed_count = str(1)   # or '3', '5' as needed\n",
    "slice_prompt = str(1)\n",
    "\n",
    "result_root = os.path.join(data_dir, f'sam2_results_by_pid_{seed_count}seed_{slice_prompt}_slice_prompt')\n",
    "img_mapping_root = os.path.join(data_dir, f'img_in_jpg_to_sam2_{seed_count}seed')\n",
    "output_csv = os.path.join(data_dir, f'{dataset}_2class_IOU_all_pid_with_full_mapping_{seed_count}seed_{slice_prompt}_slice_prompt.csv')\n",
    "\n",
    "all_records = []\n",
    "\n",
    "for pid_folder in sorted(os.listdir(result_root)):\n",
    "    iou_csv_path = os.path.join(result_root, pid_folder, f\"{pid_folder}_iou_results.csv\")\n",
    "    mapping_csv_path = os.path.join(img_mapping_root, pid_folder, f\"{pid_folder}_mapping.csv\")\n",
    "\n",
    "    if not os.path.exists(iou_csv_path) or not os.path.exists(mapping_csv_path):\n",
    "        print(f\"⚠️ 跳过 {pid_folder}，缺少 IOU 或 mapping 文件\")\n",
    "        continue\n",
    "\n",
    "    df_iou = pd.read_csv(iou_csv_path)\n",
    "    df_map = pd.read_csv(mapping_csv_path)\n",
    "\n",
    "    # 按 frame_idx 合并，保留 mapping 所有列，并附加 iou 列\n",
    "    df_merged = pd.merge(df_map, df_iou, on='frame_idx', how='left')\n",
    "\n",
    "    # 添加一列，显示当前外层 pid_folder (采集组名)\n",
    "    df_merged['pid_folder'] = pid_folder\n",
    "\n",
    "    all_records.append(df_merged)\n",
    "\n",
    "    print(f\"✅ 处理完 {pid_folder}，共 {len(df_merged)} 帧\")\n",
    "\n",
    "# 合并所有 pid_folder 的结果\n",
    "df_all = pd.concat(all_records, ignore_index=True)\n",
    "\n",
    "# 按需排序，比如 pid_folder, frame_idx\n",
    "df_all = df_all.sort_values(['pid_folder', 'frame_idx']).reset_index(drop=True)\n",
    "\n",
    "# 保存到csv\n",
    "# output_csv = os.path.join(data_dir, 'AFL_4class_IOU_all_pid_with_full_mapping.csv')\n",
    "# df_all.to_csv(output_csv, index=False)\n",
    "\n",
    "print(f\"\\n📄 保存所有合并结果至 {output_csv}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6e1eaafb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>frame_idx</th>\n",
       "      <th>pid</th>\n",
       "      <th>slice_id</th>\n",
       "      <th>src_img_file</th>\n",
       "      <th>dst_img_file</th>\n",
       "      <th>layer</th>\n",
       "      <th>category</th>\n",
       "      <th>iou_id1</th>\n",
       "      <th>iou_id2</th>\n",
       "      <th>iou_sum</th>\n",
       "      <th>pid_folder</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>word_0002_L4L5</td>\n",
       "      <td>14</td>\n",
       "      <td>word_0002_L4L5_slice_014_img.jpg</td>\n",
       "      <td>00001.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>infer</td>\n",
       "      <td>0.8591</td>\n",
       "      <td>0.9074</td>\n",
       "      <td>1.7665</td>\n",
       "      <td>word_0002_L4L5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>word_0002_L4L5</td>\n",
       "      <td>13</td>\n",
       "      <td>word_0002_L4L5_slice_013_img.jpg</td>\n",
       "      <td>00003.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>infer</td>\n",
       "      <td>0.9102</td>\n",
       "      <td>0.9114</td>\n",
       "      <td>1.8216</td>\n",
       "      <td>word_0002_L4L5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>word_0002_L4L5</td>\n",
       "      <td>12</td>\n",
       "      <td>word_0002_L4L5_slice_012_img.jpg</td>\n",
       "      <td>00005.jpg</td>\n",
       "      <td>2</td>\n",
       "      <td>infer</td>\n",
       "      <td>0.9012</td>\n",
       "      <td>0.9221</td>\n",
       "      <td>1.8233</td>\n",
       "      <td>word_0002_L4L5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>word_0002_L4L5</td>\n",
       "      <td>11</td>\n",
       "      <td>word_0002_L4L5_slice_011_img.jpg</td>\n",
       "      <td>00007.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>infer</td>\n",
       "      <td>0.8724</td>\n",
       "      <td>0.9123</td>\n",
       "      <td>1.7847</td>\n",
       "      <td>word_0002_L4L5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>word_0002_L4L5</td>\n",
       "      <td>10</td>\n",
       "      <td>word_0002_L4L5_slice_010_img.jpg</td>\n",
       "      <td>00009.jpg</td>\n",
       "      <td>4</td>\n",
       "      <td>infer</td>\n",
       "      <td>0.9083</td>\n",
       "      <td>0.9306</td>\n",
       "      <td>1.8389</td>\n",
       "      <td>word_0002_L4L5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   frame_idx             pid  slice_id                      src_img_file  \\\n",
       "0          1  word_0002_L4L5        14  word_0002_L4L5_slice_014_img.jpg   \n",
       "1          3  word_0002_L4L5        13  word_0002_L4L5_slice_013_img.jpg   \n",
       "2          5  word_0002_L4L5        12  word_0002_L4L5_slice_012_img.jpg   \n",
       "3          7  word_0002_L4L5        11  word_0002_L4L5_slice_011_img.jpg   \n",
       "4          9  word_0002_L4L5        10  word_0002_L4L5_slice_010_img.jpg   \n",
       "\n",
       "  dst_img_file  layer category  iou_id1  iou_id2  iou_sum      pid_folder  \n",
       "0    00001.jpg      0    infer   0.8591   0.9074   1.7665  word_0002_L4L5  \n",
       "1    00003.jpg      1    infer   0.9102   0.9114   1.8216  word_0002_L4L5  \n",
       "2    00005.jpg      2    infer   0.9012   0.9221   1.8233  word_0002_L4L5  \n",
       "3    00007.jpg      3    infer   0.8724   0.9123   1.7847  word_0002_L4L5  \n",
       "4    00009.jpg      4    infer   0.9083   0.9306   1.8389  word_0002_L4L5  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df_all = df_all.sort_values(['pid', 'frame_idx']).reset_index(drop=True)\n",
    "cols = ['iou_id1', 'iou_id2',  'iou_sum']\n",
    "df_all[cols] = df_all[cols].round(4)\n",
    "\n",
    "df_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "88b7f2a2-0963-48ec-b014-23a3dcc3f927",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for idx, row in df_all.iterrows():\n",
    "#     print(row['frame_idx'], row['pid'], row['slice_id'], row['category'], row['iou_id1'], row['iou_id2'], row['iou_sum'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7583a9a9-c37a-478f-b5dc-d2bbd9b4747e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>frame_idx</th>\n",
       "      <th>pid</th>\n",
       "      <th>slice_id</th>\n",
       "      <th>src_img_file</th>\n",
       "      <th>dst_img_file</th>\n",
       "      <th>layer</th>\n",
       "      <th>category</th>\n",
       "      <th>iou_id1</th>\n",
       "      <th>iou_id2</th>\n",
       "      <th>iou_sum</th>\n",
       "      <th>pid_folder</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>590</th>\n",
       "      <td>0</td>\n",
       "      <td>word_0081_L4L5</td>\n",
       "      <td>10</td>\n",
       "      <td>word_0081_L4L5_slice_010_img.jpg</td>\n",
       "      <td>00000.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>seed</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>2.0000</td>\n",
       "      <td>word_0002_L4L5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>591</th>\n",
       "      <td>0</td>\n",
       "      <td>word_0081_L4L5</td>\n",
       "      <td>10</td>\n",
       "      <td>word_0081_L4L5_slice_010_img.jpg</td>\n",
       "      <td>00000.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>seed</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>2.0000</td>\n",
       "      <td>word_0003_L4L5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>592</th>\n",
       "      <td>0</td>\n",
       "      <td>word_0081_L4L5</td>\n",
       "      <td>10</td>\n",
       "      <td>word_0081_L4L5_slice_010_img.jpg</td>\n",
       "      <td>00000.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>seed</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>2.0000</td>\n",
       "      <td>word_0004_L4L5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>593</th>\n",
       "      <td>0</td>\n",
       "      <td>word_0081_L4L5</td>\n",
       "      <td>10</td>\n",
       "      <td>word_0081_L4L5_slice_010_img.jpg</td>\n",
       "      <td>00000.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>seed</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>2.0000</td>\n",
       "      <td>word_0005_L4L5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>594</th>\n",
       "      <td>0</td>\n",
       "      <td>word_0081_L4L5</td>\n",
       "      <td>10</td>\n",
       "      <td>word_0081_L4L5_slice_010_img.jpg</td>\n",
       "      <td>00000.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>seed</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>2.0000</td>\n",
       "      <td>word_0006_L4L5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1674</th>\n",
       "      <td>20</td>\n",
       "      <td>word_0081_L4L5</td>\n",
       "      <td>0</td>\n",
       "      <td>word_0081_L4L5_slice_000_img.jpg</td>\n",
       "      <td>00020.jpg</td>\n",
       "      <td>10</td>\n",
       "      <td>seed</td>\n",
       "      <td>0.7597</td>\n",
       "      <td>0.7997</td>\n",
       "      <td>1.5594</td>\n",
       "      <td>word_0145_L4L5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1675</th>\n",
       "      <td>20</td>\n",
       "      <td>word_0081_L4L5</td>\n",
       "      <td>0</td>\n",
       "      <td>word_0081_L4L5_slice_000_img.jpg</td>\n",
       "      <td>00020.jpg</td>\n",
       "      <td>10</td>\n",
       "      <td>seed</td>\n",
       "      <td>0.7741</td>\n",
       "      <td>0.8366</td>\n",
       "      <td>1.6107</td>\n",
       "      <td>word_0146_L4L5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1676</th>\n",
       "      <td>20</td>\n",
       "      <td>word_0081_L4L5</td>\n",
       "      <td>0</td>\n",
       "      <td>word_0081_L4L5_slice_000_img.jpg</td>\n",
       "      <td>00020.jpg</td>\n",
       "      <td>10</td>\n",
       "      <td>seed</td>\n",
       "      <td>0.7070</td>\n",
       "      <td>0.7601</td>\n",
       "      <td>1.4671</td>\n",
       "      <td>word_0147_L4L5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1677</th>\n",
       "      <td>20</td>\n",
       "      <td>word_0081_L4L5</td>\n",
       "      <td>0</td>\n",
       "      <td>word_0081_L4L5_slice_000_img.jpg</td>\n",
       "      <td>00020.jpg</td>\n",
       "      <td>10</td>\n",
       "      <td>seed</td>\n",
       "      <td>0.7467</td>\n",
       "      <td>0.8312</td>\n",
       "      <td>1.5780</td>\n",
       "      <td>word_0148_L4L5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1678</th>\n",
       "      <td>20</td>\n",
       "      <td>word_0081_L4L5</td>\n",
       "      <td>0</td>\n",
       "      <td>word_0081_L4L5_slice_000_img.jpg</td>\n",
       "      <td>00020.jpg</td>\n",
       "      <td>10</td>\n",
       "      <td>seed</td>\n",
       "      <td>0.7663</td>\n",
       "      <td>0.8169</td>\n",
       "      <td>1.5832</td>\n",
       "      <td>word_0150_L4L5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1089 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      frame_idx             pid  slice_id                      src_img_file  \\\n",
       "590           0  word_0081_L4L5        10  word_0081_L4L5_slice_010_img.jpg   \n",
       "591           0  word_0081_L4L5        10  word_0081_L4L5_slice_010_img.jpg   \n",
       "592           0  word_0081_L4L5        10  word_0081_L4L5_slice_010_img.jpg   \n",
       "593           0  word_0081_L4L5        10  word_0081_L4L5_slice_010_img.jpg   \n",
       "594           0  word_0081_L4L5        10  word_0081_L4L5_slice_010_img.jpg   \n",
       "...         ...             ...       ...                               ...   \n",
       "1674         20  word_0081_L4L5         0  word_0081_L4L5_slice_000_img.jpg   \n",
       "1675         20  word_0081_L4L5         0  word_0081_L4L5_slice_000_img.jpg   \n",
       "1676         20  word_0081_L4L5         0  word_0081_L4L5_slice_000_img.jpg   \n",
       "1677         20  word_0081_L4L5         0  word_0081_L4L5_slice_000_img.jpg   \n",
       "1678         20  word_0081_L4L5         0  word_0081_L4L5_slice_000_img.jpg   \n",
       "\n",
       "     dst_img_file  layer category  iou_id1  iou_id2  iou_sum      pid_folder  \n",
       "590     00000.jpg      0     seed   1.0000   1.0000   2.0000  word_0002_L4L5  \n",
       "591     00000.jpg      0     seed   1.0000   1.0000   2.0000  word_0003_L4L5  \n",
       "592     00000.jpg      0     seed   1.0000   1.0000   2.0000  word_0004_L4L5  \n",
       "593     00000.jpg      0     seed   1.0000   1.0000   2.0000  word_0005_L4L5  \n",
       "594     00000.jpg      0     seed   1.0000   1.0000   2.0000  word_0006_L4L5  \n",
       "...           ...    ...      ...      ...      ...      ...             ...  \n",
       "1674    00020.jpg     10     seed   0.7597   0.7997   1.5594  word_0145_L4L5  \n",
       "1675    00020.jpg     10     seed   0.7741   0.8366   1.6107  word_0146_L4L5  \n",
       "1676    00020.jpg     10     seed   0.7070   0.7601   1.4671  word_0147_L4L5  \n",
       "1677    00020.jpg     10     seed   0.7467   0.8312   1.5780  word_0148_L4L5  \n",
       "1678    00020.jpg     10     seed   0.7663   0.8169   1.5832  word_0150_L4L5  \n",
       "\n",
       "[1089 rows x 11 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed_df = df_all[df_all['category'] == 'seed']\n",
    "seed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8bb68aa4-0947-413a-90dd-209e5c2ba229",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 12/12 [00:03<00:00,  3.64it/s]\n",
      "  0%|                                                    | 0/12 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copied pid word_0081_L4L5 frame 4 best pid_folder word_0146_L4L5Copied pid word_0081_L4L5 frame 8 best pid_folder word_0061_L4L5Copied pid word_0081_L4L5 frame 19 best pid_folder word_0116_L4L5Copied pid word_0081_L4L5 frame 0 best pid_folder word_0002_L4L5Copied pid word_0081_L4L5 frame 6 best pid_folder word_0104_L4L5Copied pid word_0081_L4L5 frame 14 best pid_folder word_0046_L4L5\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Copied pid word_0081_L4L5 frame 12 best pid_folder word_0082_L4L5Copied pid word_0081_L4L5 frame 18 best pid_folder word_0061_L4L5Copied pid word_0081_L4L5 frame 20 best pid_folder word_0051_L4L5Copied pid word_0081_L4L5 frame 2 best pid_folder word_0041_L4L5Copied pid word_0081_L4L5 frame 10 best pid_folder word_0127_L4L5Copied pid word_0081_L4L5 frame 16 best pid_folder word_0082_L4L5\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 12/12 [00:00<00:00, 1575.03it/s]\n"
     ]
    }
   ],
   "source": [
    "import os, glob, cv2, numpy as np, shutil\n",
    "from collections import defaultdict\n",
    "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
    "from tqdm import tqdm\n",
    "\n",
    "def dice(m1, m2):\n",
    "    # 计算两个二值mask的Dice系数\n",
    "    m1, m2 = m1 > 0, m2 > 0\n",
    "    inter = np.logical_and(m1, m2).sum()\n",
    "    union = m1.sum() + m2.sum()\n",
    "    return 1.0 if union == 0 else 2 * inter / union\n",
    "\n",
    "def compute_best_pid_folder(item):\n",
    "    # 计算每组中最一致的pid_folder\n",
    "    key, ms = item\n",
    "    if len(ms) == 1: \n",
    "        return key, ms[0]['pid_folder']\n",
    "    imgs = [{'img': cv2.imread(m['path'], 0),\n",
    "             'cls': np.unique(cv2.imread(m['path'], 0))[1:],  # 读取所有类别，排除背景0\n",
    "             'pid_folder': m['pid_folder']} for m in ms]\n",
    "    scores = []\n",
    "    n = len(imgs)\n",
    "    for i in range(n):\n",
    "        s = 0\n",
    "        for j in range(n):\n",
    "            if i == j: continue\n",
    "            common = np.intersect1d(imgs[i]['cls'], imgs[j]['cls'])\n",
    "            if not len(common): continue\n",
    "            s += np.mean([dice(imgs[i]['img'] == c, imgs[j]['img'] == c) for c in common])\n",
    "        scores.append(s/(n-1))\n",
    "    return key, imgs[np.argmax(scores)]['pid_folder']\n",
    "\n",
    "def copy_files(args):\n",
    "    # 复制对应的obj和combined分割png文件，并返回seed_df对应行\n",
    "    pid, fidx, pfolder = args\n",
    "    src = os.path.join(data_dir, f'sam2_results_by_pid_{seed_count}seed_{slice_prompt}_slice_prompt', pfolder, 'SAM2_seg_mask_nolap')\n",
    "    dst = os.path.join(data_dir, f'sam2_results_by_pid_{seed_count}seed_{slice_prompt}_slice_prompt', pid, 'SAM2_seg_mask_nolap')\n",
    "    os.makedirs(dst, exist_ok=True)\n",
    "    for f in glob.glob(os.path.join(src, f\"frame_{fidx}_obj_*.png\")) + glob.glob(os.path.join(src, f\"frame_{fidx}_combined*.png\")):\n",
    "        shutil.copy2(f, os.path.join(dst, os.path.basename(f)))\n",
    "    print(f\"Copied pid {pid} frame {fidx} best pid_folder {pfolder}\")\n",
    "    return seed_df[(seed_df.pid==pid) & (seed_df.frame_idx==fidx) & (seed_df.pid_folder==pfolder)].head(1)\n",
    "\n",
    "# 分组收集每个(pid, frame_idx)对应的合并mask路径\n",
    "grouped = defaultdict(list)\n",
    "for _, r in seed_df.iterrows():\n",
    "    pdir = os.path.join(data_dir, f'sam2_results_by_pid_{seed_count}seed_{slice_prompt}_slice_prompt', r['pid_folder'], 'SAM2_seg_mask_nolap')\n",
    "    cpath = os.path.join(pdir, f\"frame_{r['frame_idx']}_combined.png\")\n",
    "    if os.path.exists(cpath): \n",
    "        grouped[(r['pid'], r['frame_idx'])].append({'path': cpath, 'pid_folder': r['pid_folder']})\n",
    "\n",
    "# 并行计算最佳pid_folder\n",
    "with ProcessPoolExecutor(max_workers=8) as executor:\n",
    "    futures = {executor.submit(compute_best_pid_folder, item): item[0] for item in grouped.items()}\n",
    "    best_choice = {future.result()[0]: future.result()[1] for future in tqdm(as_completed(futures), total=len(futures))}\n",
    "\n",
    "seen, selected_rows, copy_args = set(), [], []\n",
    "for (pid, fidx), pfolder in best_choice.items():\n",
    "    if (pid, fidx) in seen: continue\n",
    "    seen.add((pid, fidx))\n",
    "    copy_args.append((pid, fidx, pfolder))\n",
    "\n",
    "# 并行复制文件，收集对应seed_df行\n",
    "with ProcessPoolExecutor(max_workers=6) as executor:\n",
    "    results = list(tqdm(executor.map(copy_files, copy_args), total=len(copy_args)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5efd0030-0b4a-4a87-9f06-add46c5e3fc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected rows from seed_df:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>frame_idx</th>\n",
       "      <th>pid</th>\n",
       "      <th>slice_id</th>\n",
       "      <th>src_img_file</th>\n",
       "      <th>dst_img_file</th>\n",
       "      <th>layer</th>\n",
       "      <th>category</th>\n",
       "      <th>iou_id1</th>\n",
       "      <th>iou_id2</th>\n",
       "      <th>iou_sum</th>\n",
       "      <th>pid_folder</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20</td>\n",
       "      <td>word_0081_L4L5</td>\n",
       "      <td>0</td>\n",
       "      <td>word_0081_L4L5_slice_000_img.jpg</td>\n",
       "      <td>00020.jpg</td>\n",
       "      <td>10</td>\n",
       "      <td>seed</td>\n",
       "      <td>0.7131</td>\n",
       "      <td>0.6814</td>\n",
       "      <td>1.3945</td>\n",
       "      <td>word_0051_L4L5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>word_0081_L4L5</td>\n",
       "      <td>1</td>\n",
       "      <td>word_0081_L4L5_slice_001_img.jpg</td>\n",
       "      <td>00018.jpg</td>\n",
       "      <td>9</td>\n",
       "      <td>seed</td>\n",
       "      <td>0.6282</td>\n",
       "      <td>0.6358</td>\n",
       "      <td>1.2640</td>\n",
       "      <td>word_0061_L4L5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16</td>\n",
       "      <td>word_0081_L4L5</td>\n",
       "      <td>2</td>\n",
       "      <td>word_0081_L4L5_slice_002_img.jpg</td>\n",
       "      <td>00016.jpg</td>\n",
       "      <td>8</td>\n",
       "      <td>seed</td>\n",
       "      <td>0.7024</td>\n",
       "      <td>0.7496</td>\n",
       "      <td>1.4520</td>\n",
       "      <td>word_0082_L4L5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14</td>\n",
       "      <td>word_0081_L4L5</td>\n",
       "      <td>3</td>\n",
       "      <td>word_0081_L4L5_slice_003_img.jpg</td>\n",
       "      <td>00014.jpg</td>\n",
       "      <td>7</td>\n",
       "      <td>seed</td>\n",
       "      <td>0.6861</td>\n",
       "      <td>0.8355</td>\n",
       "      <td>1.5216</td>\n",
       "      <td>word_0046_L4L5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12</td>\n",
       "      <td>word_0081_L4L5</td>\n",
       "      <td>4</td>\n",
       "      <td>word_0081_L4L5_slice_004_img.jpg</td>\n",
       "      <td>00012.jpg</td>\n",
       "      <td>6</td>\n",
       "      <td>seed</td>\n",
       "      <td>0.7604</td>\n",
       "      <td>0.8515</td>\n",
       "      <td>1.6119</td>\n",
       "      <td>word_0082_L4L5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10</td>\n",
       "      <td>word_0081_L4L5</td>\n",
       "      <td>5</td>\n",
       "      <td>word_0081_L4L5_slice_005_img.jpg</td>\n",
       "      <td>00010.jpg</td>\n",
       "      <td>5</td>\n",
       "      <td>seed</td>\n",
       "      <td>0.8528</td>\n",
       "      <td>0.8711</td>\n",
       "      <td>1.7239</td>\n",
       "      <td>word_0127_L4L5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8</td>\n",
       "      <td>word_0081_L4L5</td>\n",
       "      <td>6</td>\n",
       "      <td>word_0081_L4L5_slice_006_img.jpg</td>\n",
       "      <td>00008.jpg</td>\n",
       "      <td>4</td>\n",
       "      <td>seed</td>\n",
       "      <td>0.8739</td>\n",
       "      <td>0.9043</td>\n",
       "      <td>1.7782</td>\n",
       "      <td>word_0061_L4L5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6</td>\n",
       "      <td>word_0081_L4L5</td>\n",
       "      <td>7</td>\n",
       "      <td>word_0081_L4L5_slice_007_img.jpg</td>\n",
       "      <td>00006.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>seed</td>\n",
       "      <td>0.8647</td>\n",
       "      <td>0.8870</td>\n",
       "      <td>1.7516</td>\n",
       "      <td>word_0104_L4L5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4</td>\n",
       "      <td>word_0081_L4L5</td>\n",
       "      <td>8</td>\n",
       "      <td>word_0081_L4L5_slice_008_img.jpg</td>\n",
       "      <td>00004.jpg</td>\n",
       "      <td>2</td>\n",
       "      <td>seed</td>\n",
       "      <td>0.8474</td>\n",
       "      <td>0.9063</td>\n",
       "      <td>1.7537</td>\n",
       "      <td>word_0146_L4L5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>word_0081_L4L5</td>\n",
       "      <td>9</td>\n",
       "      <td>word_0081_L4L5_slice_009_img.jpg</td>\n",
       "      <td>00002.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>seed</td>\n",
       "      <td>0.8981</td>\n",
       "      <td>0.9197</td>\n",
       "      <td>1.8177</td>\n",
       "      <td>word_0041_L4L5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>word_0081_L4L5</td>\n",
       "      <td>10</td>\n",
       "      <td>word_0081_L4L5_slice_010_img.jpg</td>\n",
       "      <td>00000.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>seed</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>2.0000</td>\n",
       "      <td>word_0002_L4L5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    frame_idx             pid  slice_id                      src_img_file  \\\n",
       "0          20  word_0081_L4L5         0  word_0081_L4L5_slice_000_img.jpg   \n",
       "1          18  word_0081_L4L5         1  word_0081_L4L5_slice_001_img.jpg   \n",
       "2          16  word_0081_L4L5         2  word_0081_L4L5_slice_002_img.jpg   \n",
       "3          14  word_0081_L4L5         3  word_0081_L4L5_slice_003_img.jpg   \n",
       "4          12  word_0081_L4L5         4  word_0081_L4L5_slice_004_img.jpg   \n",
       "5          10  word_0081_L4L5         5  word_0081_L4L5_slice_005_img.jpg   \n",
       "6           8  word_0081_L4L5         6  word_0081_L4L5_slice_006_img.jpg   \n",
       "7           6  word_0081_L4L5         7  word_0081_L4L5_slice_007_img.jpg   \n",
       "8           4  word_0081_L4L5         8  word_0081_L4L5_slice_008_img.jpg   \n",
       "9           2  word_0081_L4L5         9  word_0081_L4L5_slice_009_img.jpg   \n",
       "10          0  word_0081_L4L5        10  word_0081_L4L5_slice_010_img.jpg   \n",
       "\n",
       "   dst_img_file  layer category  iou_id1  iou_id2  iou_sum      pid_folder  \n",
       "0     00020.jpg     10     seed   0.7131   0.6814   1.3945  word_0051_L4L5  \n",
       "1     00018.jpg      9     seed   0.6282   0.6358   1.2640  word_0061_L4L5  \n",
       "2     00016.jpg      8     seed   0.7024   0.7496   1.4520  word_0082_L4L5  \n",
       "3     00014.jpg      7     seed   0.6861   0.8355   1.5216  word_0046_L4L5  \n",
       "4     00012.jpg      6     seed   0.7604   0.8515   1.6119  word_0082_L4L5  \n",
       "5     00010.jpg      5     seed   0.8528   0.8711   1.7239  word_0127_L4L5  \n",
       "6     00008.jpg      4     seed   0.8739   0.9043   1.7782  word_0061_L4L5  \n",
       "7     00006.jpg      3     seed   0.8647   0.8870   1.7516  word_0104_L4L5  \n",
       "8     00004.jpg      2     seed   0.8474   0.9063   1.7537  word_0146_L4L5  \n",
       "9     00002.jpg      1     seed   0.8981   0.9197   1.8177  word_0041_L4L5  \n",
       "10    00000.jpg      0     seed   1.0000   1.0000   2.0000  word_0002_L4L5  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# 合并所有选中行输出\n",
    "selected_df_raw = pd.concat(results, ignore_index=True)\n",
    "# 先按 slice_id 和 iou_sum 排序，iou_sum 降序保证最高的在前面\n",
    "df_sorted = selected_df_raw.sort_values(by=['slice_id', 'iou_sum'], ascending=[True, False])\n",
    "\n",
    "# 按 slice_id 去重，保留第一条（即 iou_sum 最高的）\n",
    "selected_df = df_sorted.drop_duplicates(subset=['slice_id'], keep='first').reset_index(drop=True)\n",
    "\n",
    "print(\"Selected rows from seed_df:\")\n",
    "selected_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "825d77aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_filter 满足条件的行数: 1207\n",
      "df_filter + seed_rows 满足条件的行数 : 1218\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>frame_idx</th>\n",
       "      <th>pid</th>\n",
       "      <th>slice_id</th>\n",
       "      <th>src_img_file</th>\n",
       "      <th>dst_img_file</th>\n",
       "      <th>layer</th>\n",
       "      <th>category</th>\n",
       "      <th>iou_id1</th>\n",
       "      <th>iou_id2</th>\n",
       "      <th>iou_sum</th>\n",
       "      <th>pid_folder</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>word_0002_L4L5</td>\n",
       "      <td>14</td>\n",
       "      <td>word_0002_L4L5_slice_014_img.jpg</td>\n",
       "      <td>00001.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>infer</td>\n",
       "      <td>0.8591</td>\n",
       "      <td>0.9074</td>\n",
       "      <td>1.7665</td>\n",
       "      <td>word_0002_L4L5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>word_0002_L4L5</td>\n",
       "      <td>13</td>\n",
       "      <td>word_0002_L4L5_slice_013_img.jpg</td>\n",
       "      <td>00003.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>infer</td>\n",
       "      <td>0.9102</td>\n",
       "      <td>0.9114</td>\n",
       "      <td>1.8216</td>\n",
       "      <td>word_0002_L4L5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>word_0002_L4L5</td>\n",
       "      <td>12</td>\n",
       "      <td>word_0002_L4L5_slice_012_img.jpg</td>\n",
       "      <td>00005.jpg</td>\n",
       "      <td>2</td>\n",
       "      <td>infer</td>\n",
       "      <td>0.9012</td>\n",
       "      <td>0.9221</td>\n",
       "      <td>1.8233</td>\n",
       "      <td>word_0002_L4L5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>word_0002_L4L5</td>\n",
       "      <td>11</td>\n",
       "      <td>word_0002_L4L5_slice_011_img.jpg</td>\n",
       "      <td>00007.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>infer</td>\n",
       "      <td>0.8724</td>\n",
       "      <td>0.9123</td>\n",
       "      <td>1.7847</td>\n",
       "      <td>word_0002_L4L5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>word_0002_L4L5</td>\n",
       "      <td>10</td>\n",
       "      <td>word_0002_L4L5_slice_010_img.jpg</td>\n",
       "      <td>00009.jpg</td>\n",
       "      <td>4</td>\n",
       "      <td>infer</td>\n",
       "      <td>0.9083</td>\n",
       "      <td>0.9306</td>\n",
       "      <td>1.8389</td>\n",
       "      <td>word_0002_L4L5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8</td>\n",
       "      <td>word_0081_L4L5</td>\n",
       "      <td>6</td>\n",
       "      <td>word_0081_L4L5_slice_006_img.jpg</td>\n",
       "      <td>00008.jpg</td>\n",
       "      <td>4</td>\n",
       "      <td>seed</td>\n",
       "      <td>0.8739</td>\n",
       "      <td>0.9043</td>\n",
       "      <td>1.7782</td>\n",
       "      <td>word_0061_L4L5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6</td>\n",
       "      <td>word_0081_L4L5</td>\n",
       "      <td>7</td>\n",
       "      <td>word_0081_L4L5_slice_007_img.jpg</td>\n",
       "      <td>00006.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>seed</td>\n",
       "      <td>0.8647</td>\n",
       "      <td>0.8870</td>\n",
       "      <td>1.7516</td>\n",
       "      <td>word_0104_L4L5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4</td>\n",
       "      <td>word_0081_L4L5</td>\n",
       "      <td>8</td>\n",
       "      <td>word_0081_L4L5_slice_008_img.jpg</td>\n",
       "      <td>00004.jpg</td>\n",
       "      <td>2</td>\n",
       "      <td>seed</td>\n",
       "      <td>0.8474</td>\n",
       "      <td>0.9063</td>\n",
       "      <td>1.7537</td>\n",
       "      <td>word_0146_L4L5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>word_0081_L4L5</td>\n",
       "      <td>9</td>\n",
       "      <td>word_0081_L4L5_slice_009_img.jpg</td>\n",
       "      <td>00002.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>seed</td>\n",
       "      <td>0.8981</td>\n",
       "      <td>0.9197</td>\n",
       "      <td>1.8177</td>\n",
       "      <td>word_0041_L4L5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>word_0081_L4L5</td>\n",
       "      <td>10</td>\n",
       "      <td>word_0081_L4L5_slice_010_img.jpg</td>\n",
       "      <td>00000.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>seed</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>2.0000</td>\n",
       "      <td>word_0002_L4L5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1218 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    frame_idx             pid  slice_id                      src_img_file  \\\n",
       "0           1  word_0002_L4L5        14  word_0002_L4L5_slice_014_img.jpg   \n",
       "1           3  word_0002_L4L5        13  word_0002_L4L5_slice_013_img.jpg   \n",
       "2           5  word_0002_L4L5        12  word_0002_L4L5_slice_012_img.jpg   \n",
       "3           7  word_0002_L4L5        11  word_0002_L4L5_slice_011_img.jpg   \n",
       "4           9  word_0002_L4L5        10  word_0002_L4L5_slice_010_img.jpg   \n",
       "..        ...             ...       ...                               ...   \n",
       "6           8  word_0081_L4L5         6  word_0081_L4L5_slice_006_img.jpg   \n",
       "7           6  word_0081_L4L5         7  word_0081_L4L5_slice_007_img.jpg   \n",
       "8           4  word_0081_L4L5         8  word_0081_L4L5_slice_008_img.jpg   \n",
       "9           2  word_0081_L4L5         9  word_0081_L4L5_slice_009_img.jpg   \n",
       "10          0  word_0081_L4L5        10  word_0081_L4L5_slice_010_img.jpg   \n",
       "\n",
       "   dst_img_file  layer category  iou_id1  iou_id2  iou_sum      pid_folder  \n",
       "0     00001.jpg      0    infer   0.8591   0.9074   1.7665  word_0002_L4L5  \n",
       "1     00003.jpg      1    infer   0.9102   0.9114   1.8216  word_0002_L4L5  \n",
       "2     00005.jpg      2    infer   0.9012   0.9221   1.8233  word_0002_L4L5  \n",
       "3     00007.jpg      3    infer   0.8724   0.9123   1.7847  word_0002_L4L5  \n",
       "4     00009.jpg      4    infer   0.9083   0.9306   1.8389  word_0002_L4L5  \n",
       "..          ...    ...      ...      ...      ...      ...             ...  \n",
       "6     00008.jpg      4     seed   0.8739   0.9043   1.7782  word_0061_L4L5  \n",
       "7     00006.jpg      3     seed   0.8647   0.8870   1.7516  word_0104_L4L5  \n",
       "8     00004.jpg      2     seed   0.8474   0.9063   1.7537  word_0146_L4L5  \n",
       "9     00002.jpg      1     seed   0.8981   0.9197   1.8177  word_0041_L4L5  \n",
       "10    00000.jpg      0     seed   1.0000   1.0000   2.0000  word_0002_L4L5  \n",
       "\n",
       "[1218 rows x 11 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filter = df_all[df_all['category'] != 'seed'].copy()\n",
    "print(f\"df_filter 满足条件的行数: {len(df_filter)}\")\n",
    "df_filter = pd.concat([df_filter,selected_df])\n",
    "\n",
    "df_filter.to_csv(output_csv, index=False)\n",
    "print(f\"df_filter + seed_rows 满足条件的行数 : {len(df_filter)}\")\n",
    "\n",
    "df_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5b38fe8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import SimpleITK as sitk\n",
    "import numpy as np\n",
    "import cv2\n",
    "from scipy.ndimage import label, binary_fill_holes\n",
    "\n",
    "def save_array_to_nii(mask_array, nii_template_path, nii_save_path):\n",
    "\n",
    "    sitk_image_object = sitk.ReadImage(nii_template_path)\n",
    "    output_spacing = sitk_image_object.GetSpacing()\n",
    "    output_direction = sitk_image_object.GetDirection()\n",
    "    output_origin = sitk_image_object.GetOrigin()\n",
    "#     print(output_spacing ,output_direction,output_origin)\n",
    "\n",
    "    nrrd_output = sitk.GetImageFromArray(mask_array)\n",
    "    nrrd_output.SetSpacing(output_spacing)\n",
    "    nrrd_output.SetDirection(output_direction)\n",
    "    nrrd_output.SetOrigin(output_origin)\n",
    "\n",
    "    nrrdWriter = sitk.ImageFileWriter()\n",
    "    nrrdWriter.SetFileName(nii_save_path)\n",
    "    nrrdWriter.SetUseCompression(True)\n",
    "    nrrdWriter.Execute(nrrd_output)\n",
    "    print(nii_save_path ,'saved')\n",
    "    \n",
    "\n",
    "\n",
    "def keep_largest_connected_component(mask):\n",
    "    mask = mask.astype(np.uint8)\n",
    "\n",
    "    if mask.ndim == 3:\n",
    "        # Handle 3D mask with scipy\n",
    "        structure = np.ones((3, 3, 3), dtype=np.uint8)\n",
    "        labeled, num = label(mask, structure=structure)\n",
    "        if num == 0:\n",
    "            return mask\n",
    "        counts = np.bincount(labeled.ravel())\n",
    "        counts[0] = 0  # background\n",
    "        largest_label = np.argmax(counts)\n",
    "        return (labeled == largest_label).astype(np.uint8)\n",
    "\n",
    "    elif mask.ndim == 2:\n",
    "        # Handle 2D mask with OpenCV\n",
    "        if mask.ndim != 2 or mask.shape[0] == 0 or mask.shape[1] == 0:\n",
    "            raise ValueError(f\"Invalid 2D mask shape: {mask.shape}\")\n",
    "        num_labels, labels, stats, _ = cv2.connectedComponentsWithStats(mask, connectivity=8)\n",
    "        if num_labels <= 1:\n",
    "            return mask\n",
    "        largest = 1 + np.argmax(stats[1:, cv2.CC_STAT_AREA])\n",
    "        return (labels == largest).astype(np.uint8)\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported mask dimension: {mask.ndim}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1e955f5d-7fd1-40f6-8716-cb63196bf522",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                   | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ File exists, skipping: videos/CT_word/data_in_nii/SAM2_auto_seg_nii_1shot_2class_1_slice_prompt/word_0002_L4L5_sam2_seg_2class.nii.gz⚠️ File exists, skipping: videos/CT_word/data_in_nii/SAM2_auto_seg_nii_1shot_2class_1_slice_prompt/word_0003_L4L5_sam2_seg_2class.nii.gz\n",
      "⚠️ File exists, skipping: videos/CT_word/data_in_nii/SAM2_auto_seg_nii_1shot_2class_1_slice_prompt/word_0010_L4L5_sam2_seg_2class.nii.gz\n",
      "\n",
      "⚠️ File exists, skipping: videos/CT_word/data_in_nii/SAM2_auto_seg_nii_1shot_2class_1_slice_prompt/word_0005_L4L5_sam2_seg_2class.nii.gz⚠️ File exists, skipping: videos/CT_word/data_in_nii/SAM2_auto_seg_nii_1shot_2class_1_slice_prompt/word_0004_L4L5_sam2_seg_2class.nii.gz⚠️ File exists, skipping: videos/CT_word/data_in_nii/SAM2_auto_seg_nii_1shot_2class_1_slice_prompt/word_0006_L4L5_sam2_seg_2class.nii.gz⚠️ File exists, skipping: videos/CT_word/data_in_nii/SAM2_auto_seg_nii_1shot_2class_1_slice_prompt/word_0008_L4L5_sam2_seg_2class.nii.gz⚠️ File exists, skipping: videos/CT_word/data_in_nii/SAM2_auto_seg_nii_1shot_2class_1_slice_prompt/word_0009_L4L5_sam2_seg_2class.nii.gz⚠️ File exists, skipping: videos/CT_word/data_in_nii/SAM2_auto_seg_nii_1shot_2class_1_slice_prompt/word_0011_L4L5_sam2_seg_2class.nii.gz⚠️ File exists, skipping: videos/CT_word/data_in_nii/SAM2_auto_seg_nii_1shot_2class_1_slice_prompt/word_0013_L4L5_sam2_seg_2class.nii.gz\n",
      "\n",
      "⚠️ File exists, skipping: videos/CT_word/data_in_nii/SAM2_auto_seg_nii_1shot_2class_1_slice_prompt/word_0012_L4L5_sam2_seg_2class.nii.gz\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 100/100 [00:00<00:00, 5105.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "⚠️ File exists, skipping: videos/CT_word/data_in_nii/SAM2_auto_seg_nii_1shot_2class_1_slice_prompt/word_0018_L4L5_sam2_seg_2class.nii.gz⚠️ File exists, skipping: videos/CT_word/data_in_nii/SAM2_auto_seg_nii_1shot_2class_1_slice_prompt/word_0027_L4L5_sam2_seg_2class.nii.gz⚠️ File exists, skipping: videos/CT_word/data_in_nii/SAM2_auto_seg_nii_1shot_2class_1_slice_prompt/word_0020_L4L5_sam2_seg_2class.nii.gz"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ File exists, skipping: videos/CT_word/data_in_nii/SAM2_auto_seg_nii_1shot_2class_1_slice_prompt/word_0022_L4L5_sam2_seg_2class.nii.gz⚠️ File exists, skipping: videos/CT_word/data_in_nii/SAM2_auto_seg_nii_1shot_2class_1_slice_prompt/word_0026_L4L5_sam2_seg_2class.nii.gz⚠️ File exists, skipping: videos/CT_word/data_in_nii/SAM2_auto_seg_nii_1shot_2class_1_slice_prompt/word_0028_L4L5_sam2_seg_2class.nii.gz⚠️ File exists, skipping: videos/CT_word/data_in_nii/SAM2_auto_seg_nii_1shot_2class_1_slice_prompt/word_0029_L4L5_sam2_seg_2class.nii.gz\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "⚠️ File exists, skipping: videos/CT_word/data_in_nii/SAM2_auto_seg_nii_1shot_2class_1_slice_prompt/word_0030_L4L5_sam2_seg_2class.nii.gz\n",
      "⚠️ File exists, skipping: videos/CT_word/data_in_nii/SAM2_auto_seg_nii_1shot_2class_1_slice_prompt/word_0032_L4L5_sam2_seg_2class.nii.gz\n",
      "⚠️ File exists, skipping: videos/CT_word/data_in_nii/SAM2_auto_seg_nii_1shot_2class_1_slice_prompt/word_0038_L4L5_sam2_seg_2class.nii.gz⚠️ File exists, skipping: videos/CT_word/data_in_nii/SAM2_auto_seg_nii_1shot_2class_1_slice_prompt/word_0036_L4L5_sam2_seg_2class.nii.gz⚠️ File exists, skipping: videos/CT_word/data_in_nii/SAM2_auto_seg_nii_1shot_2class_1_slice_prompt/word_0040_L4L5_sam2_seg_2class.nii.gz\n",
      "⚠️ File exists, skipping: videos/CT_word/data_in_nii/SAM2_auto_seg_nii_1shot_2class_1_slice_prompt/word_0041_L4L5_sam2_seg_2class.nii.gz⚠️ File exists, skipping: videos/CT_word/data_in_nii/SAM2_auto_seg_nii_1shot_2class_1_slice_prompt/word_0042_L4L5_sam2_seg_2class.nii.gz⚠️ File exists, skipping: videos/CT_word/data_in_nii/SAM2_auto_seg_nii_1shot_2class_1_slice_prompt/word_0044_L4L5_sam2_seg_2class.nii.gz\n",
      "\n",
      "\n",
      "\n",
      "⚠️ File exists, skipping: videos/CT_word/data_in_nii/SAM2_auto_seg_nii_1shot_2class_1_slice_prompt/word_0046_L4L5_sam2_seg_2class.nii.gz⚠️ File exists, skipping: videos/CT_word/data_in_nii/SAM2_auto_seg_nii_1shot_2class_1_slice_prompt/word_0047_L4L5_sam2_seg_2class.nii.gz\n",
      "\n",
      "\n",
      "\n",
      "⚠️ File exists, skipping: videos/CT_word/data_in_nii/SAM2_auto_seg_nii_1shot_2class_1_slice_prompt/word_0051_L4L5_sam2_seg_2class.nii.gz⚠️ File exists, skipping: videos/CT_word/data_in_nii/SAM2_auto_seg_nii_1shot_2class_1_slice_prompt/word_0055_L4L5_sam2_seg_2class.nii.gz⚠️ File exists, skipping: videos/CT_word/data_in_nii/SAM2_auto_seg_nii_1shot_2class_1_slice_prompt/word_0049_L4L5_sam2_seg_2class.nii.gz⚠️ File exists, skipping: videos/CT_word/data_in_nii/SAM2_auto_seg_nii_1shot_2class_1_slice_prompt/word_0053_L4L5_sam2_seg_2class.nii.gz⚠️ File exists, skipping: videos/CT_word/data_in_nii/SAM2_auto_seg_nii_1shot_2class_1_slice_prompt/word_0059_L4L5_sam2_seg_2class.nii.gz⚠️ File exists, skipping: videos/CT_word/data_in_nii/SAM2_auto_seg_nii_1shot_2class_1_slice_prompt/word_0058_L4L5_sam2_seg_2class.nii.gz\n",
      "⚠️ File exists, skipping: videos/CT_word/data_in_nii/SAM2_auto_seg_nii_1shot_2class_1_slice_prompt/word_0056_L4L5_sam2_seg_2class.nii.gz\n",
      "⚠️ File exists, skipping: videos/CT_word/data_in_nii/SAM2_auto_seg_nii_1shot_2class_1_slice_prompt/word_0061_L4L5_sam2_seg_2class.nii.gz\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "⚠️ File exists, skipping: videos/CT_word/data_in_nii/SAM2_auto_seg_nii_1shot_2class_1_slice_prompt/word_0062_L4L5_sam2_seg_2class.nii.gz⚠️ File exists, skipping: videos/CT_word/data_in_nii/SAM2_auto_seg_nii_1shot_2class_1_slice_prompt/word_0063_L4L5_sam2_seg_2class.nii.gz⚠️ File exists, skipping: videos/CT_word/data_in_nii/SAM2_auto_seg_nii_1shot_2class_1_slice_prompt/word_0065_L4L5_sam2_seg_2class.nii.gz⚠️ File exists, skipping: videos/CT_word/data_in_nii/SAM2_auto_seg_nii_1shot_2class_1_slice_prompt/word_0064_L4L5_sam2_seg_2class.nii.gz⚠️ File exists, skipping: videos/CT_word/data_in_nii/SAM2_auto_seg_nii_1shot_2class_1_slice_prompt/word_0067_L4L5_sam2_seg_2class.nii.gz⚠️ File exists, skipping: videos/CT_word/data_in_nii/SAM2_auto_seg_nii_1shot_2class_1_slice_prompt/word_0068_L4L5_sam2_seg_2class.nii.gz⚠️ File exists, skipping: videos/CT_word/data_in_nii/SAM2_auto_seg_nii_1shot_2class_1_slice_prompt/word_0070_L4L5_sam2_seg_2class.nii.gz\n",
      "\n",
      "⚠️ File exists, skipping: videos/CT_word/data_in_nii/SAM2_auto_seg_nii_1shot_2class_1_slice_prompt/word_0071_L4L5_sam2_seg_2class.nii.gz\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "⚠️ File exists, skipping: videos/CT_word/data_in_nii/SAM2_auto_seg_nii_1shot_2class_1_slice_prompt/word_0073_L4L5_sam2_seg_2class.nii.gz⚠️ File exists, skipping: videos/CT_word/data_in_nii/SAM2_auto_seg_nii_1shot_2class_1_slice_prompt/word_0072_L4L5_sam2_seg_2class.nii.gz⚠️ File exists, skipping: videos/CT_word/data_in_nii/SAM2_auto_seg_nii_1shot_2class_1_slice_prompt/word_0078_L4L5_sam2_seg_2class.nii.gz⚠️ File exists, skipping: videos/CT_word/data_in_nii/SAM2_auto_seg_nii_1shot_2class_1_slice_prompt/word_0079_L4L5_sam2_seg_2class.nii.gz⚠️ File exists, skipping: videos/CT_word/data_in_nii/SAM2_auto_seg_nii_1shot_2class_1_slice_prompt/word_0081_L4L5_sam2_seg_2class.nii.gz\n",
      "⚠️ File exists, skipping: videos/CT_word/data_in_nii/SAM2_auto_seg_nii_1shot_2class_1_slice_prompt/word_0084_L4L5_sam2_seg_2class.nii.gz⚠️ File exists, skipping: videos/CT_word/data_in_nii/SAM2_auto_seg_nii_1shot_2class_1_slice_prompt/word_0082_L4L5_sam2_seg_2class.nii.gz\n",
      "⚠️ File exists, skipping: videos/CT_word/data_in_nii/SAM2_auto_seg_nii_1shot_2class_1_slice_prompt/word_0086_L4L5_sam2_seg_2class.nii.gz\n",
      "\n",
      "\n",
      "\n",
      "⚠️ File exists, skipping: videos/CT_word/data_in_nii/SAM2_auto_seg_nii_1shot_2class_1_slice_prompt/word_0087_L4L5_sam2_seg_2class.nii.gz\n",
      "\n",
      "⚠️ File exists, skipping: videos/CT_word/data_in_nii/SAM2_auto_seg_nii_1shot_2class_1_slice_prompt/word_0089_L4L5_sam2_seg_2class.nii.gz⚠️ File exists, skipping: videos/CT_word/data_in_nii/SAM2_auto_seg_nii_1shot_2class_1_slice_prompt/word_0090_L4L5_sam2_seg_2class.nii.gz⚠️ File exists, skipping: videos/CT_word/data_in_nii/SAM2_auto_seg_nii_1shot_2class_1_slice_prompt/word_0091_L4L5_sam2_seg_2class.nii.gz\n",
      "⚠️ File exists, skipping: videos/CT_word/data_in_nii/SAM2_auto_seg_nii_1shot_2class_1_slice_prompt/word_0094_L4L5_sam2_seg_2class.nii.gz\n",
      "\n",
      "⚠️ File exists, skipping: videos/CT_word/data_in_nii/SAM2_auto_seg_nii_1shot_2class_1_slice_prompt/word_0093_L4L5_sam2_seg_2class.nii.gz⚠️ File exists, skipping: videos/CT_word/data_in_nii/SAM2_auto_seg_nii_1shot_2class_1_slice_prompt/word_0095_L4L5_sam2_seg_2class.nii.gz\n",
      "⚠️ File exists, skipping: videos/CT_word/data_in_nii/SAM2_auto_seg_nii_1shot_2class_1_slice_prompt/word_0096_L4L5_sam2_seg_2class.nii.gz\n",
      "\n",
      "\n",
      "\n",
      "⚠️ File exists, skipping: videos/CT_word/data_in_nii/SAM2_auto_seg_nii_1shot_2class_1_slice_prompt/word_0101_L4L5_sam2_seg_2class.nii.gz⚠️ File exists, skipping: videos/CT_word/data_in_nii/SAM2_auto_seg_nii_1shot_2class_1_slice_prompt/word_0100_L4L5_sam2_seg_2class.nii.gz⚠️ File exists, skipping: videos/CT_word/data_in_nii/SAM2_auto_seg_nii_1shot_2class_1_slice_prompt/word_0102_L4L5_sam2_seg_2class.nii.gz⚠️ File exists, skipping: videos/CT_word/data_in_nii/SAM2_auto_seg_nii_1shot_2class_1_slice_prompt/word_0104_L4L5_sam2_seg_2class.nii.gz⚠️ File exists, skipping: videos/CT_word/data_in_nii/SAM2_auto_seg_nii_1shot_2class_1_slice_prompt/word_0105_L4L5_sam2_seg_2class.nii.gz\n",
      "\n",
      "\n",
      "⚠️ File exists, skipping: videos/CT_word/data_in_nii/SAM2_auto_seg_nii_1shot_2class_1_slice_prompt/word_0106_L4L5_sam2_seg_2class.nii.gz⚠️ File exists, skipping: videos/CT_word/data_in_nii/SAM2_auto_seg_nii_1shot_2class_1_slice_prompt/word_0107_L4L5_sam2_seg_2class.nii.gz\n",
      "⚠️ File exists, skipping: videos/CT_word/data_in_nii/SAM2_auto_seg_nii_1shot_2class_1_slice_prompt/word_0108_L4L5_sam2_seg_2class.nii.gz\n",
      "\n",
      "\n",
      "⚠️ File exists, skipping: videos/CT_word/data_in_nii/SAM2_auto_seg_nii_1shot_2class_1_slice_prompt/word_0111_L4L5_sam2_seg_2class.nii.gz⚠️ File exists, skipping: videos/CT_word/data_in_nii/SAM2_auto_seg_nii_1shot_2class_1_slice_prompt/word_0109_L4L5_sam2_seg_2class.nii.gz\n",
      "⚠️ File exists, skipping: videos/CT_word/data_in_nii/SAM2_auto_seg_nii_1shot_2class_1_slice_prompt/word_0114_L4L5_sam2_seg_2class.nii.gz⚠️ File exists, skipping: videos/CT_word/data_in_nii/SAM2_auto_seg_nii_1shot_2class_1_slice_prompt/word_0113_L4L5_sam2_seg_2class.nii.gz⚠️ File exists, skipping: videos/CT_word/data_in_nii/SAM2_auto_seg_nii_1shot_2class_1_slice_prompt/word_0115_L4L5_sam2_seg_2class.nii.gz\n",
      "⚠️ File exists, skipping: videos/CT_word/data_in_nii/SAM2_auto_seg_nii_1shot_2class_1_slice_prompt/word_0116_L4L5_sam2_seg_2class.nii.gz\n",
      "\n",
      "⚠️ File exists, skipping: videos/CT_word/data_in_nii/SAM2_auto_seg_nii_1shot_2class_1_slice_prompt/word_0117_L4L5_sam2_seg_2class.nii.gz\n",
      "\n",
      "\n",
      "⚠️ File exists, skipping: videos/CT_word/data_in_nii/SAM2_auto_seg_nii_1shot_2class_1_slice_prompt/word_0121_L4L5_sam2_seg_2class.nii.gz⚠️ File exists, skipping: videos/CT_word/data_in_nii/SAM2_auto_seg_nii_1shot_2class_1_slice_prompt/word_0118_L4L5_sam2_seg_2class.nii.gz\n",
      "⚠️ File exists, skipping: videos/CT_word/data_in_nii/SAM2_auto_seg_nii_1shot_2class_1_slice_prompt/word_0122_L4L5_sam2_seg_2class.nii.gz⚠️ File exists, skipping: videos/CT_word/data_in_nii/SAM2_auto_seg_nii_1shot_2class_1_slice_prompt/word_0119_L4L5_sam2_seg_2class.nii.gz\n",
      "⚠️ File exists, skipping: videos/CT_word/data_in_nii/SAM2_auto_seg_nii_1shot_2class_1_slice_prompt/word_0125_L4L5_sam2_seg_2class.nii.gz⚠️ File exists, skipping: videos/CT_word/data_in_nii/SAM2_auto_seg_nii_1shot_2class_1_slice_prompt/word_0123_L4L5_sam2_seg_2class.nii.gz⚠️ File exists, skipping: videos/CT_word/data_in_nii/SAM2_auto_seg_nii_1shot_2class_1_slice_prompt/word_0126_L4L5_sam2_seg_2class.nii.gz\n",
      "\n",
      "\n",
      "\n",
      "⚠️ File exists, skipping: videos/CT_word/data_in_nii/SAM2_auto_seg_nii_1shot_2class_1_slice_prompt/word_0127_L4L5_sam2_seg_2class.nii.gz\n",
      "\n",
      "⚠️ File exists, skipping: videos/CT_word/data_in_nii/SAM2_auto_seg_nii_1shot_2class_1_slice_prompt/word_0128_L4L5_sam2_seg_2class.nii.gz⚠️ File exists, skipping: videos/CT_word/data_in_nii/SAM2_auto_seg_nii_1shot_2class_1_slice_prompt/word_0130_L4L5_sam2_seg_2class.nii.gz⚠️ File exists, skipping: videos/CT_word/data_in_nii/SAM2_auto_seg_nii_1shot_2class_1_slice_prompt/word_0133_L4L5_sam2_seg_2class.nii.gz⚠️ File exists, skipping: videos/CT_word/data_in_nii/SAM2_auto_seg_nii_1shot_2class_1_slice_prompt/word_0132_L4L5_sam2_seg_2class.nii.gz\n",
      "⚠️ File exists, skipping: videos/CT_word/data_in_nii/SAM2_auto_seg_nii_1shot_2class_1_slice_prompt/word_0134_L4L5_sam2_seg_2class.nii.gz\n",
      "⚠️ File exists, skipping: videos/CT_word/data_in_nii/SAM2_auto_seg_nii_1shot_2class_1_slice_prompt/word_0135_L4L5_sam2_seg_2class.nii.gz\n",
      "\n",
      "⚠️ File exists, skipping: videos/CT_word/data_in_nii/SAM2_auto_seg_nii_1shot_2class_1_slice_prompt/word_0136_L4L5_sam2_seg_2class.nii.gz\n",
      "⚠️ File exists, skipping: videos/CT_word/data_in_nii/SAM2_auto_seg_nii_1shot_2class_1_slice_prompt/word_0138_L4L5_sam2_seg_2class.nii.gz\n",
      "\n",
      "⚠️ File exists, skipping: videos/CT_word/data_in_nii/SAM2_auto_seg_nii_1shot_2class_1_slice_prompt/word_0140_L4L5_sam2_seg_2class.nii.gz⚠️ File exists, skipping: videos/CT_word/data_in_nii/SAM2_auto_seg_nii_1shot_2class_1_slice_prompt/word_0142_L4L5_sam2_seg_2class.nii.gz\n",
      "\n",
      "⚠️ File exists, skipping: videos/CT_word/data_in_nii/SAM2_auto_seg_nii_1shot_2class_1_slice_prompt/word_0143_L4L5_sam2_seg_2class.nii.gz\n",
      "\n",
      "\n",
      "⚠️ File exists, skipping: videos/CT_word/data_in_nii/SAM2_auto_seg_nii_1shot_2class_1_slice_prompt/word_0144_L4L5_sam2_seg_2class.nii.gz⚠️ File exists, skipping: videos/CT_word/data_in_nii/SAM2_auto_seg_nii_1shot_2class_1_slice_prompt/word_0145_L4L5_sam2_seg_2class.nii.gz⚠️ File exists, skipping: videos/CT_word/data_in_nii/SAM2_auto_seg_nii_1shot_2class_1_slice_prompt/word_0147_L4L5_sam2_seg_2class.nii.gz⚠️ File exists, skipping: videos/CT_word/data_in_nii/SAM2_auto_seg_nii_1shot_2class_1_slice_prompt/word_0148_L4L5_sam2_seg_2class.nii.gz⚠️ File exists, skipping: videos/CT_word/data_in_nii/SAM2_auto_seg_nii_1shot_2class_1_slice_prompt/word_0146_L4L5_sam2_seg_2class.nii.gz\n",
      "⚠️ File exists, skipping: videos/CT_word/data_in_nii/SAM2_auto_seg_nii_1shot_2class_1_slice_prompt/word_0150_L4L5_sam2_seg_2class.nii.gz\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os, glob, cv2, numpy as np, pandas as pd, SimpleITK as sitk\n",
    "from tqdm import tqdm\n",
    "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
    "\n",
    "def save_array_to_nii(arr, ref_path, save_path):\n",
    "    img = sitk.ReadImage(ref_path)\n",
    "    out = sitk.GetImageFromArray(arr)\n",
    "    out.CopyInformation(img)\n",
    "    sitk.WriteImage(out, save_path)\n",
    "\n",
    "def process_pid(item):\n",
    "    pid, group = item\n",
    "    try:\n",
    "        save_path = os.path.join(save_seg_dir, f\"{pid}_sam2_seg_2class.nii.gz\")\n",
    "        if os.path.exists(save_path):\n",
    "            print(f\"⚠️ File exists, skipping: {save_path}\")\n",
    "            return\n",
    "        group = group.sort_values('slice_id')\n",
    "        frame_ids, slice_ids = group['frame_idx'].tolist(), group['slice_id'].tolist()\n",
    "        img_path_list = glob.glob(os.path.join(img_dir, f\"{pid}*.nii.gz\"))\n",
    "        if not img_path_list:\n",
    "            print(f\"❌ No image for {pid}\")\n",
    "            return\n",
    "        img_path = img_path_list[0]\n",
    "        img = sitk.ReadImage(img_path)\n",
    "        H, W = sitk.GetArrayFromImage(img).shape[1:]\n",
    "        seg_array = []\n",
    "        pred_dir = os.path.join(sam2_root, pid, 'SAM2_seg_mask_nolap')\n",
    "\n",
    "        for f_id, s_id in zip(frame_ids, slice_ids):\n",
    "            multi_mask = np.zeros((H, W), dtype=np.uint8)\n",
    "            for obj_idx in [1, 2]:\n",
    "                png_path = os.path.join(pred_dir, f\"frame_{f_id}_obj_{obj_idx}.png\")\n",
    "                if not os.path.exists(png_path):\n",
    "                    continue\n",
    "                mask = cv2.imread(png_path, cv2.IMREAD_GRAYSCALE)\n",
    "                if mask is None or mask.max() == 0:\n",
    "                    continue\n",
    "                values = np.unique(mask)\n",
    "                values = values[values > 0]\n",
    "                if len(values) == 0:\n",
    "                    continue\n",
    "                mask_bin = (mask == values[0]).astype(np.uint8)\n",
    "                mask_clean = keep_largest_connected_component(mask_bin)\n",
    "                mask_resized = cv2.resize(mask_clean, (W, H), interpolation=cv2.INTER_NEAREST)\n",
    "                multi_mask[mask_resized > 0] = obj_idx\n",
    "            if 'ID' in pid or 'CT_TT' in dataset:\n",
    "                multi_mask = np.rot90(multi_mask, 2)\n",
    "            seg_array.append(multi_mask)\n",
    "        if not seg_array:\n",
    "            print(f\"⚠️ No valid masks for {pid}, skipping.\")\n",
    "            return\n",
    "        seg_stack = np.stack(seg_array)\n",
    "        for cls in [1, 2]:\n",
    "            cls_mask = (seg_stack == cls).astype(np.uint8)\n",
    "            cleaned = keep_largest_connected_component(cls_mask)\n",
    "            seg_stack[seg_stack == cls] = 0\n",
    "            seg_stack[cleaned > 0] = cls\n",
    "        save_array_to_nii(seg_stack, img_path, save_path)\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error processing {pid}: {e}\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    base_dir = f'videos/{dataset}'\n",
    "    seed_str = str(seed_count)\n",
    "    data_dir = os.path.join(base_dir, 'data_in_jpg_2class')\n",
    "    csv_path = os.path.join(data_dir, f'{dataset}_2class_IOU_all_pid_with_full_mapping_{seed_count}seed_{slice_prompt}_slice_prompt.csv')\n",
    "\n",
    "    img_dir = os.path.join(base_dir, 'data_in_nii', 'img_in_nii_L4L5')\n",
    "    sam2_root = os.path.join(data_dir, f'sam2_results_by_pid_{seed_count}seed_{slice_prompt}_slice_prompt')\n",
    "    save_seg_dir = os.path.join(base_dir, f'data_in_nii/SAM2_auto_seg_nii_{seed_str}shot_2class_{slice_prompt}_slice_prompt')\n",
    "    os.makedirs(save_seg_dir, exist_ok=True)\n",
    "\n",
    "    df = pd.read_csv(csv_path)\n",
    "    with ProcessPoolExecutor(max_workers=8) as executor:\n",
    "        futures = {executor.submit(process_pid, item): item[0] for item in df.groupby('pid')}\n",
    "        for future in tqdm(as_completed(futures), total=len(futures)):\n",
    "            future.result()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3e9dff41-9622-4d42-b1e3-28f6abe25f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os, glob\n",
    "# import numpy as np\n",
    "# import SimpleITK as sitk\n",
    "# from tqdm import tqdm\n",
    "\n",
    "# def convert_to_2class_label(input_path, output_path):\n",
    "#     \"\"\"Convert a 4-class label to 2-class and save.\"\"\"\n",
    "#     img = sitk.ReadImage(input_path)\n",
    "#     arr = sitk.GetArrayFromImage(img)\n",
    "\n",
    "#     arr_out = np.zeros_like(arr, dtype=np.uint8)\n",
    "#     arr_out[np.isin(arr, [1, 2])] = 1\n",
    "#     arr_out[np.isin(arr, [3, 4])] = 2\n",
    "\n",
    "#     img_out = sitk.GetImageFromArray(arr_out)\n",
    "#     img_out.CopyInformation(img)\n",
    "#     sitk.WriteImage(img_out, output_path)\n",
    "\n",
    "# # === Config ===\n",
    "# base_dir = f'videos/{dataset}'\n",
    "\n",
    "# label_subdir = 'label_in_nii_72_water_72_L4L5' if dataset == 'Bedrest' else 'label_in_nii_L4L5_4class'\n",
    "\n",
    "# input_dir = os.path.join(base_dir, 'data_in_nii', label_subdir)\n",
    "# output_dir = os.path.join(base_dir, 'data_in_nii', label_subdir.replace('_4class', '') + '_2class')\n",
    "\n",
    "# os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# # === Convert All ===\n",
    "# nii_files = glob.glob(os.path.join(input_dir, '*.nii.gz'))\n",
    "\n",
    "# for in_path in tqdm(nii_files, desc=f\"Converting {dataset} to 2-class\"):\n",
    "#     fname = os.path.basename(in_path)\n",
    "#     out_path = os.path.join(output_dir, fname.replace('.nii.gz', '_2class.nii.gz'))\n",
    "    \n",
    "#     if not os.path.exists(out_path):\n",
    "#         convert_to_2class_label(in_path, out_path)\n",
    "# print(f\"\\n✅ Done. 2-class labels saved to: {output_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3ffe274d-023e-463a-8911-1cf62e7ec40b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DSC: 100%|████████████████████████████████████| 100/100 [00:06<00:00, 14.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ DSC saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os, glob, numpy as np, pandas as pd, SimpleITK as sitk\n",
    "from tqdm import tqdm\n",
    "\n",
    "def dice(pred, gt, cls):\n",
    "    p = (pred == cls).astype(np.uint8)\n",
    "    g = (gt == cls).astype(np.uint8)\n",
    "\n",
    "    p_lcc = keep_largest_connected_component(p)\n",
    "    g_lcc = keep_largest_connected_component(g)\n",
    "\n",
    "    s = p_lcc.sum() + g_lcc.sum()\n",
    "    if s == 0:\n",
    "        return 1.0\n",
    "    intersection = np.logical_and(p_lcc, g_lcc).sum()\n",
    "    return 2 * intersection / s\n",
    "\n",
    "save_dir = os.path.join(base_dir, f'data_in_nii/SAM2_auto_seg_nii_{seed_str}shot_2class_{slice_prompt}_slice_prompt')\n",
    "label_subdir = 'label_in_nii_72_water_72_L4L5' if dataset == 'Bedrest' else 'label_in_nii_L4L5_4class'\n",
    "label_dir = os.path.join(base_dir, 'data_in_nii', label_subdir.replace('_4class', '') + '_2class')\n",
    "\n",
    "results = []\n",
    "for pred_path in tqdm(glob.glob(os.path.join(save_dir, '*.nii.gz')), desc='DSC'):\n",
    "    pid = os.path.basename(pred_path).split('_sam2_seg_2class')[0]\n",
    "    gt_paths = glob.glob(os.path.join(label_dir, f\"{pid}*.nii.gz\"))\n",
    "    if not gt_paths:\n",
    "        print(f\"⚠️ GT missing: {pid}\")\n",
    "        continue\n",
    "    pred = sitk.GetArrayFromImage(sitk.ReadImage(pred_path))\n",
    "    gt = sitk.GetArrayFromImage(sitk.ReadImage(gt_paths[0]))\n",
    "    results.append([pid, dice(pred, gt, 1), dice(pred, gt, 2)])\n",
    "\n",
    "df = pd.DataFrame(results, columns=['pid', 'dsc_class1', 'dsc_class2'])\n",
    "df.to_csv(os.path.join(base_dir, f'{dataset}_SAM2_auto_seg_DSC_summary_{seed_str}seed_2class.csv'), index=False)\n",
    "\n",
    "print('✅ DSC saved')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b30394f7-d966-4a86-b2ac-0341fd4a8979",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CT_word 1 shots\n",
      "CT_word 1 slice_prompt\n",
      "Mean ± Std DSC per class:\n",
      "dsc_class1: 0.901 ± 0.034\n",
      "dsc_class2: 0.903 ± 0.036\n",
      "\n",
      "Data shape: (100, 3)\n"
     ]
    }
   ],
   "source": [
    "print(f\"{dataset} {seed_count} shots\")\n",
    "print(f\"{dataset} {slice_prompt} slice_prompt\")\n",
    "\n",
    "mean_values = df[['dsc_class1', 'dsc_class2']].mean()\n",
    "std_values = df[['dsc_class1', 'dsc_class2']].std()\n",
    "\n",
    "print(\"Mean ± Std DSC per class:\")\n",
    "for cls in ['dsc_class1', 'dsc_class2']:\n",
    "    print(f\"{cls}: {mean_values[cls]:.3f} ± {std_values[cls]:.3f}\")\n",
    "\n",
    "print(f\"\\nData shape: {df.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41376ea1-9936-469c-bf73-1eb6a885545c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfaf16c5-303f-4423-a53f-032b65146e7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f3465be1-59c8-42ea-8d5f-32f7d6a64beb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MRI515_T2 1 shots\n",
      "MRI515_T2 1 slice_prompt\n",
      "Mean ± Std DSC per class:\n",
      "dsc_class1: 0.933 ± 0.020\n",
      "dsc_class2: 0.937 ± 0.029\n",
      "\n",
      "Data shape: (411, 3)\n",
      "       pid  dsc_class1  dsc_class2\n",
      "0  0408_T2    0.941029    0.928850\n",
      "1  0365_T2    0.944793    0.959493\n",
      "2  0116_T2    0.921510    0.934275\n",
      "3  0105_T2    0.944610    0.933386\n",
      "4  0474_T2    0.948064    0.941004\n"
     ]
    }
   ],
   "source": [
    "print(f\"{dataset} {seed_count} shots\")\n",
    "print(f\"{dataset} {slice_prompt} slice_prompt\")\n",
    "\n",
    "mean_values = df[['dsc_class1', 'dsc_class2']].mean()\n",
    "std_values = df[['dsc_class1', 'dsc_class2']].std()\n",
    "\n",
    "print(\"Mean ± Std DSC per class:\")\n",
    "for cls in ['dsc_class1', 'dsc_class2']:\n",
    "    print(f\"{cls}: {mean_values[cls]:.3f} ± {std_values[cls]:.3f}\")\n",
    "\n",
    "print(f\"\\nData shape: {df.shape}\")\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e072b0a-854f-4305-8283-9c4814268bbd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d4b898-ef5f-40ba-bf43-1de88ed4f2bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
