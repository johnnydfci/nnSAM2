{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3a42d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "from transformers import AutoImageProcessor, AutoModel\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# ==========================\n",
    "# 1. Setup\n",
    "# ==========================\n",
    "# Input directory containing patient subfolders with slice images (.jpg).\n",
    "# ‚ö†Ô∏è Update this path to match your dataset.\n",
    "infer_dir = 'videos/CT_word/data_in_jpg_2class/img_in_jpg'\n",
    "\n",
    "# Device configuration (use GPU if available, otherwise fall back to CPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Initialize DINOv2 feature extractor and model\n",
    "processor = AutoImageProcessor.from_pretrained(\"facebook/dinov2-large\")\n",
    "model = AutoModel.from_pretrained(\"facebook/dinov2-large\").to(device)\n",
    "model.eval()\n",
    "\n",
    "# ==========================\n",
    "# 2. Helper functions\n",
    "# ==========================\n",
    "def extract_slice_number(filename):\n",
    "    \"\"\"Extract numeric slice index from filename (expects 'slice_xxx').\"\"\"\n",
    "    m = re.search(r\"slice_(\\d+)\", filename)\n",
    "    return int(m.group(1)) if m else -1\n",
    "\n",
    "def get_image_embedding(image_path):\n",
    "    \"\"\"Compute DINOv2 embedding for a single image.\"\"\"\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    inputs = processor(image, return_tensors=\"pt\").to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    return outputs.last_hidden_state.mean(dim=1).cpu().numpy()\n",
    "\n",
    "def get_patient_embedding(img_files, pid_path):\n",
    "    \"\"\"\n",
    "    Compute a representative embedding for a patient by averaging three key slices:\n",
    "      - First slice  ‚Üí approximates the L3/L4 disc level\n",
    "      - Middle slice ‚Üí approximates the L4/L5 disc level\n",
    "      - Last slice   ‚Üí approximates the L5/S1 disc level\n",
    "    \"\"\"\n",
    "    img_files.sort(key=extract_slice_number)\n",
    "    if not img_files:\n",
    "        return None\n",
    "    \n",
    "    first_img = os.path.join(pid_path, img_files[0])\n",
    "    mid_img = os.path.join(pid_path, img_files[len(img_files) // 2])\n",
    "    last_img = os.path.join(pid_path, img_files[-1])\n",
    "    \n",
    "    embeddings = [get_image_embedding(p) for p in [first_img, mid_img, last_img]]\n",
    "    return np.mean(embeddings, axis=0)\n",
    "\n",
    "# ==========================\n",
    "# 3. Collect embeddings\n",
    "# ==========================\n",
    "pid_list = []\n",
    "embeddings = []\n",
    "\n",
    "for pid in os.listdir(infer_dir):\n",
    "    pid_path = os.path.join(infer_dir, pid)\n",
    "    if not os.path.isdir(pid_path):\n",
    "        continue\n",
    "\n",
    "    img_files = [f for f in os.listdir(pid_path) if f.lower().endswith(\".jpg\")]\n",
    "    if not img_files:\n",
    "        continue\n",
    "\n",
    "    emb = get_patient_embedding(img_files, pid_path)\n",
    "    if emb is None:\n",
    "        continue\n",
    "\n",
    "    pid_list.append(pid)\n",
    "    embeddings.append(emb)\n",
    "\n",
    "print(f\"‚úÖ Found {len(pid_list)} patients. Extracting embeddings...\")\n",
    "\n",
    "# ==========================\n",
    "# 4. Compute distances\n",
    "# ==========================\n",
    "embeddings = np.vstack(embeddings)\n",
    "sim_matrix = cosine_similarity(embeddings)\n",
    "dist_matrix = 1 - sim_matrix\n",
    "\n",
    "# Compute average distance to all other patients\n",
    "avg_distances = dist_matrix.sum(axis=1) / (len(pid_list) - 1)\n",
    "\n",
    "# Select the most representative patient (lowest average distance)\n",
    "top_index = np.argmin(avg_distances)\n",
    "top_pid = pid_list[top_index]\n",
    "\n",
    "# ==========================\n",
    "# 5. Output result\n",
    "# ==========================\n",
    "print(\"\\nüéØ Most representative patient (Top-1):\")\n",
    "print(f\"- {top_pid}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ba3634",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import shutil\n",
    "import pandas as pd\n",
    "\n",
    "# ==========================\n",
    "# Configuration\n",
    "# ==========================\n",
    "dataset = \"CT_word\"\n",
    "\n",
    "# Top-1 seed patient ID (selected as the most representative patient).\n",
    "# ‚ö†Ô∏è Update this value manually based on the output from the previous step.\n",
    "# Example: seed_pid = \"word_0081_L4L5\"\n",
    "seed_pid = top_pid   # or replace with a fixed string if not running interactively\n",
    "\n",
    "# Input directories (update according to your dataset structure)\n",
    "infer_dir = f\"videos/{dataset}/data_in_jpg_2class/img_in_jpg\"\n",
    "label_dir = f\"videos/{dataset}/data_in_jpg_2class/label_in_png\"\n",
    "\n",
    "# Output directories (new datasets for SAM2 training with one seed)\n",
    "output_img_base_dir = f\"videos/{dataset}/data_in_jpg_2class/img_in_jpg_to_sam2_1seed\"\n",
    "output_label_base_dir = f\"videos/{dataset}/data_in_jpg_2class/label_in_png_to_sam2_1seed\"\n",
    "\n",
    "\n",
    "def get_sorted_files(pid_dir):\n",
    "    \"\"\"\n",
    "    Return all slice files in a patient directory, sorted by slice index (descending).\n",
    "    Expected file naming convention: 'slice_xxx.jpg' or 'slice_xxx.png'.\n",
    "    \"\"\"\n",
    "    files = [f for f in os.listdir(pid_dir) if f.lower().endswith((\".jpg\", \".png\"))]\n",
    "\n",
    "    def extract_slice_idx(fname):\n",
    "        m = re.search(r\"slice_(\\d+)\", fname)\n",
    "        return int(m.group(1)) if m else -1\n",
    "\n",
    "    files.sort(key=extract_slice_idx, reverse=True)\n",
    "    return [os.path.join(pid_dir, f) for f in files]\n",
    "\n",
    "\n",
    "def process_with_single_seed(seed_pid):\n",
    "    \"\"\"\n",
    "    Combine slices from one seed patient and each inference patient to create\n",
    "    paired datasets for SAM2 training.\n",
    "\n",
    "    Args:\n",
    "        seed_pid (str): Patient ID selected as the seed (reference).\n",
    "    \"\"\"\n",
    "    # Exclude the seed from inference list\n",
    "    all_pids = [d for d in os.listdir(infer_dir) if os.path.isdir(os.path.join(infer_dir, d))]\n",
    "    infer_pids = [pid for pid in all_pids if pid != seed_pid]\n",
    "\n",
    "    print(f\"\\n=== üîÅ Processing with single seed ===\")\n",
    "    print(f\"Using seed_pid: {seed_pid}\")\n",
    "    print(f\"Inference PIDs: {infer_pids}\")\n",
    "\n",
    "    for infer_pid in infer_pids:\n",
    "        print(f\"\\nüöÄ Processing inference PID: {infer_pid}\")\n",
    "\n",
    "        # Create target directories for this patient\n",
    "        img_targ_dir = os.path.join(output_img_base_dir, infer_pid)\n",
    "        label_targ_dir = os.path.join(output_label_base_dir, infer_pid)\n",
    "        os.makedirs(img_targ_dir, exist_ok=True)\n",
    "        os.makedirs(label_targ_dir, exist_ok=True)\n",
    "\n",
    "        # Merge seed + current inference patient\n",
    "        pids_all = [seed_pid, infer_pid]\n",
    "\n",
    "        pid_to_img_slices = {pid: get_sorted_files(os.path.join(infer_dir, pid)) for pid in pids_all}\n",
    "        pid_to_label_slices = {pid: get_sorted_files(os.path.join(label_dir, pid)) for pid in pids_all}\n",
    "\n",
    "        global_id = 0\n",
    "        max_slices = max(len(slices) for slices in pid_to_img_slices.values())\n",
    "        mapping_records = []\n",
    "\n",
    "        # Interleave slices layer by layer\n",
    "        for layer in range(max_slices):\n",
    "            for pid in pids_all:\n",
    "                img_slices = pid_to_img_slices[pid]\n",
    "                label_slices = pid_to_label_slices[pid]\n",
    "\n",
    "                if layer < len(img_slices) and layer < len(label_slices):\n",
    "                    # Copy image slice\n",
    "                    src_img_path = img_slices[layer]\n",
    "                    img_ext = os.path.splitext(src_img_path)[1][1:]\n",
    "                    dst_img_name = f\"{str(global_id).zfill(5)}.{img_ext}\"\n",
    "                    dst_img_path = os.path.join(img_targ_dir, dst_img_name)\n",
    "                    shutil.copy(src_img_path, dst_img_path)\n",
    "\n",
    "                    # Copy label slice\n",
    "                    src_label_path = label_slices[layer]\n",
    "                    label_ext = os.path.splitext(src_label_path)[1][1:]\n",
    "                    dst_label_name = f\"{str(global_id).zfill(5)}.{label_ext}\"\n",
    "                    dst_label_path = os.path.join(label_targ_dir, dst_label_name)\n",
    "                    shutil.copy(src_label_path, dst_label_path)\n",
    "\n",
    "                    # Record mapping metadata\n",
    "                    src_img_file = os.path.basename(src_img_path)\n",
    "                    m = re.search(r\"slice_(\\d+)\", src_img_file)\n",
    "                    slice_id = int(m.group(1)) if m else -1\n",
    "                    category = \"seed\" if pid == seed_pid else \"infer\"\n",
    "\n",
    "                    mapping_records.append({\n",
    "                        \"frame_idx\": global_id,\n",
    "                        \"pid\": pid,\n",
    "                        \"slice_id\": slice_id,\n",
    "                        \"src_img_file\": src_img_file,\n",
    "                        \"dst_img_file\": dst_img_name,\n",
    "                        \"layer\": layer,\n",
    "                        \"category\": category\n",
    "                    })\n",
    "\n",
    "                    global_id += 1\n",
    "\n",
    "        # Save mapping table (for traceability)\n",
    "        mapping_df = pd.DataFrame(mapping_records)\n",
    "        mapping_csv_path = os.path.join(img_targ_dir, f\"{infer_pid}_mapping.csv\")\n",
    "        mapping_df.to_csv(mapping_csv_path, index=False)\n",
    "\n",
    "        print(f\"‚úÖ Copied images and labels to: {img_targ_dir} / {label_targ_dir}\")\n",
    "        print(f\"‚úÖ Mapping table saved to: {mapping_csv_path}\")\n",
    "\n",
    "\n",
    "# ==========================\n",
    "# Run single-seed processing\n",
    "# ==========================\n",
    "process_with_single_seed(seed_pid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7269f788",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e33f7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d674dc25",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
