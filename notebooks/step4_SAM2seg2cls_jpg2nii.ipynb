{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c8cb22b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob, re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import SimpleITK as sitk\n",
    "from tqdm import tqdm\n",
    "from scipy.ndimage import label, binary_fill_holes\n",
    "\n",
    "def save_array_to_nii(mask_array, nii_template_path, nii_save_path):\n",
    "    \"\"\"\n",
    "    Save a NumPy array as a NIfTI file, keeping metadata from template.\n",
    "    \"\"\"\n",
    "    template_img = sitk.ReadImage(nii_template_path)\n",
    "    output_img = sitk.GetImageFromArray(mask_array)\n",
    "    output_img.SetSpacing(template_img.GetSpacing())\n",
    "    output_img.SetDirection(template_img.GetDirection())\n",
    "    output_img.SetOrigin(template_img.GetOrigin())\n",
    "\n",
    "    writer = sitk.ImageFileWriter()\n",
    "    writer.SetFileName(nii_save_path)\n",
    "    writer.SetUseCompression(True)\n",
    "    writer.Execute(output_img)\n",
    "    print(f\"üíæ Saved: {nii_save_path}\")\n",
    "\n",
    "def keep_largest_connected_component(mask):\n",
    "    \"\"\"\n",
    "    Keep the largest connected component in a binary mask and fill small holes.\n",
    "    Works for both 2D and 3D masks.\n",
    "    \"\"\"\n",
    "    labeled, num = label(mask)\n",
    "    if num == 0:\n",
    "        return mask\n",
    "    counts = np.bincount(labeled.ravel())\n",
    "    counts[0] = 0  # ignore background\n",
    "    largest_label = counts.argmax()\n",
    "    return binary_fill_holes((labeled == largest_label)).astype(np.uint8)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe8d9595",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"CT_word\"   # e.g. \"AFL_MRI\", \"Bedrest\", \"CT_TT\"\n",
    "seed_count = 1\n",
    "\n",
    "# Base directories\n",
    "base_dir = f\"videos/{dataset}\"\n",
    "data_dir = os.path.join(base_dir, \"data_in_jpg\")\n",
    "csv_path = os.path.join(data_dir, f\"{dataset}_4class_IOU_all_pid_with_full_mapping_{seed_count}seed.csv\")\n",
    "\n",
    "# NIfTI input & output\n",
    "img_dir = os.path.join(base_dir, \"data_in_nii\", \"img_in_nii_L4L5\")\n",
    "save_seg_dir = os.path.join(base_dir, \"data_in_nii\", f\"SAM2_auto_seg_nii_{seed_count}shot\")\n",
    "os.makedirs(save_seg_dir, exist_ok=True)\n",
    "\n",
    "# SAM2 prediction results\n",
    "sam2_root = os.path.join(data_dir, f\"sam2_results_by_pid_{seed_count}seed\")\n",
    "\n",
    "# Special case for Bedrest dataset\n",
    "if dataset == \"Bedrest\":\n",
    "    img_dir = os.path.join(base_dir, \"data_in_nii\", \"img_in_nii_water_72_L4L5\")\n",
    "\n",
    "# Grayscale values corresponding to each class\n",
    "class_values = [100, 200]\n",
    "\n",
    "# Load IOU mapping CSV\n",
    "df = pd.read_csv(csv_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec8a358",
   "metadata": {},
   "outputs": [],
   "source": [
    "for pid, group in tqdm(df.groupby(\"pid\"), desc=\"Processing PIDs\"):\n",
    "    group = group.sort_values(\"slice_id\").reset_index(drop=True)\n",
    "    frame_ids = group[\"frame_idx\"].tolist()\n",
    "    slice_ids = group[\"slice_id\"].tolist()\n",
    "\n",
    "    # Locate input NIfTI\n",
    "    nii_files = glob.glob(os.path.join(img_dir, f\"{pid}*.nii.gz\"))\n",
    "    if not nii_files:\n",
    "        print(f\"‚ùå Image not found for {pid}\")\n",
    "        continue\n",
    "    img_path = nii_files[0]\n",
    "    img_array = sitk.GetArrayFromImage(sitk.ReadImage(img_path))\n",
    "    H, W = img_array.shape[1:]\n",
    "\n",
    "    sam2_pred_dir = os.path.join(sam2_root, pid, \"SAM2_seg_mask_nolap\")\n",
    "\n",
    "    seg_array = []\n",
    "    for frame_id, slice_id in zip(frame_ids, slice_ids):\n",
    "        per_class_masks = []\n",
    "        for i, class_val in enumerate(class_values):\n",
    "            mask_path = os.path.join(sam2_pred_dir, f\"frame_{frame_id}_obj_{i+1}.png\")\n",
    "            if not os.path.exists(mask_path):\n",
    "                print(f\"‚ö†Ô∏è Missing mask: {mask_path}\")\n",
    "                continue\n",
    "\n",
    "            mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "            mask_bin = (np.abs(mask - class_val) < 10).astype(np.uint8)\n",
    "            mask_clean = keep_largest_connected_component(mask_bin)\n",
    "            mask_resized = cv2.resize(mask_clean, (W, H), interpolation=cv2.INTER_NEAREST)\n",
    "            per_class_masks.append(mask_resized)\n",
    "\n",
    "        if len(per_class_masks) != len(class_values):\n",
    "            print(f\"‚ùå Incomplete masks for {pid} frame {frame_id}, skipping\")\n",
    "            continue\n",
    "\n",
    "        # Merge class masks\n",
    "        multi_mask = np.zeros((H, W), dtype=np.uint8)\n",
    "        for cls_idx, binary_mask in enumerate(per_class_masks):\n",
    "            multi_mask[binary_mask > 0] = cls_idx + 1\n",
    "\n",
    "        # Fix orientation for some datasets\n",
    "        if \"ID\" in pid or \"CT_TT\" in dataset:\n",
    "            multi_mask = np.rot90(multi_mask, 2)\n",
    "\n",
    "        seg_array.append(multi_mask)\n",
    "\n",
    "    if not seg_array:\n",
    "        print(f\"‚ö†Ô∏è No valid masks for {pid}, skipping saving\")\n",
    "        continue\n",
    "\n",
    "    # Stack slices into 3D\n",
    "    seg_stack = np.stack(seg_array)\n",
    "\n",
    "    # Clean each class with largest connected component\n",
    "    for class_idx in range(1, len(class_values) + 1):\n",
    "        class_mask_3d = (seg_stack == class_idx).astype(np.uint8)\n",
    "        class_mask_3d_clean = keep_largest_connected_component(class_mask_3d)\n",
    "        seg_stack[seg_stack == class_idx] = 0\n",
    "        seg_stack[class_mask_3d_clean > 0] = class_idx\n",
    "\n",
    "    # Save NIfTI\n",
    "    save_path = os.path.join(save_seg_dir, f\"{pid}_sam2_seg.nii.gz\")\n",
    "    save_array_to_nii(seg_stack, img_path, save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f53032d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================\n",
    "# Dice Coefficient Evaluation\n",
    "# ================================\n",
    "\n",
    "import os, glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import SimpleITK as sitk\n",
    "from tqdm import tqdm\n",
    "\n",
    "def dice_coefficient(pred, gt, class_id):\n",
    "    \"\"\"\n",
    "    Compute Dice similarity coefficient (DSC) for a given class.\n",
    "    \"\"\"\n",
    "    pred_bin = (pred == class_id)\n",
    "    gt_bin = (gt == class_id)\n",
    "    intersection = np.sum(pred_bin & gt_bin)\n",
    "    volume_sum = np.sum(pred_bin) + np.sum(gt_bin)\n",
    "    if volume_sum == 0:  # handle empty masks\n",
    "        return 1.0\n",
    "    return 2 * intersection / volume_sum\n",
    "\n",
    "\n",
    "# --- Directories ---\n",
    "base_dir = f\"videos/{dataset}\"\n",
    "label_dir = os.path.join(base_dir, \"data_in_nii\", \"label_in_nii_L4L5_2class\")\n",
    "if dataset == \"Bedrest\":\n",
    "    label_dir = os.path.join(base_dir, \"data_in_nii\", \"label_in_nii_72_water_72_L4L5\")\n",
    "\n",
    "# --- Class IDs to evaluate ---\n",
    "class_ids = [1, 2]\n",
    "\n",
    "# --- Collect results ---\n",
    "results = []\n",
    "for fname in tqdm(os.listdir(save_seg_dir), desc=\"Evaluating DSC\"):\n",
    "    if not fname.endswith(\".nii.gz\"):\n",
    "        continue\n",
    "\n",
    "    pid = (\n",
    "        fname.replace(\"_sam2_seg.nii.gz\", \"\")\n",
    "             .replace(\"_L4L5_lcc_combined.nii.gz\", \"\")\n",
    "    )\n",
    "    pred_path = os.path.join(save_seg_dir, fname)\n",
    "    label_candidates = glob.glob(os.path.join(label_dir, f\"{pid}*.nii.gz\"))\n",
    "\n",
    "    if not label_candidates:\n",
    "        print(f\"‚ö†Ô∏è Label not found for {pid}, skipping.\")\n",
    "        continue\n",
    "\n",
    "    label_path = label_candidates[0]\n",
    "\n",
    "    # Load prediction & ground truth\n",
    "    pred = sitk.GetArrayFromImage(sitk.ReadImage(pred_path))\n",
    "    gt = sitk.GetArrayFromImage(sitk.ReadImage(label_path))\n",
    "\n",
    "    # Compute Dice per class\n",
    "    dscs = [dice_coefficient(pred, gt, c) for c in class_ids]\n",
    "    results.append([pid, *dscs])\n",
    "\n",
    "# --- Save summary ---\n",
    "df = pd.DataFrame(results, columns=[\"pid\"] + [f\"dsc_class{c}\" for c in class_ids])\n",
    "out_csv = os.path.join(base_dir, f\"{dataset}_SAM2_auto_seg_DSC_summary_{seed_count}seed.csv\")\n",
    "df.to_csv(out_csv, index=False)\n",
    "\n",
    "print(f\"üìÑ DSC summary saved to: {out_csv}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74516f01-f7e4-4a86-8fc4-83902ef2178a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================\n",
    "# DSC Statistics (Mean ¬± Std)\n",
    "# ================================\n",
    "\n",
    "print(f\"üìä Dataset: {dataset}\")\n",
    "\n",
    "# Compute mean and std for selected classes\n",
    "selected_cols = [\"dsc_class1\", \"dsc_class2\"]\n",
    "mean_values = df[selected_cols].mean()\n",
    "std_values = df[selected_cols].std()\n",
    "\n",
    "print(\"\\nüìà Mean DSC per class:\")\n",
    "for cls, val in mean_values.items():\n",
    "    print(f\"  {cls}: {val:.4f}\")\n",
    "\n",
    "print(\"\\nüìâ Standard Deviation of DSC per class:\")\n",
    "for cls, val in std_values.items():\n",
    "    print(f\"  {cls}: {val:.4f}\")\n",
    "\n",
    "# Show summary info\n",
    "print(f\"\\n‚úÖ Total cases evaluated: {df.shape[0]}\")\n",
    "\n",
    "# Preview first rows\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37fa0a27-135b-4687-b2e7-9be05e033f6a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
